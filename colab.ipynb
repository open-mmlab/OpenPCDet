{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Git_repos.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "45bb55f5bf6d47ec8bf5b94d7b3d3d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad0b866844534feeac3c2084216036a3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a36f336accb4875815f9ff8736da348",
              "IPY_MODEL_bf2141a4c38b47238a916a1d7a360c8a",
              "IPY_MODEL_eb2dd9b130894f7c83af4da259f41af2"
            ]
          }
        },
        "ad0b866844534feeac3c2084216036a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a36f336accb4875815f9ff8736da348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c69ab3c07ce34c029db2a55fe8d0bb6b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 41%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_acad5a95d4724ddc9793db7949cd1181"
          }
        },
        "bf2141a4c38b47238a916a1d7a360c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0efd75ae684245798c412c1f22585f77",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 300000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 122429,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35cd9de15a134c41ab4e56de3d93d8aa"
          }
        },
        "eb2dd9b130894f7c83af4da259f41af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e68d5700b7fd4ab6a4ff550912612b4f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 122429/300000 [2:17:58&lt;5:49:39,  8.46it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba696c25fb814586babbfbabdc4fd53d"
          }
        },
        "c69ab3c07ce34c029db2a55fe8d0bb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "acad5a95d4724ddc9793db7949cd1181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0efd75ae684245798c412c1f22585f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35cd9de15a134c41ab4e56de3d93d8aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e68d5700b7fd4ab6a4ff550912612b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba696c25fb814586babbfbabdc4fd53d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33d6f6065f3f47cabcdfbe3eb66cec0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e0470e69f5ee422ebdb8f52e103ec8c1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9ba970c589ba499a8c1517dda5e5c3d3",
              "IPY_MODEL_77ba069e5cf44e379931e6ab3d8dca4b",
              "IPY_MODEL_73822e6403614dc8b9bd69b574255f9e"
            ]
          }
        },
        "e0470e69f5ee422ebdb8f52e103ec8c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ba970c589ba499a8c1517dda5e5c3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc08c71f784e4a2a9eddeb2de95c8792",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad662c6fcfad4fe2bbf4df8ef79bc73a"
          }
        },
        "77ba069e5cf44e379931e6ab3d8dca4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_176645ddbf0844aebed638f535015063",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2324b127888048b7ae800836db3c3a99"
          }
        },
        "73822e6403614dc8b9bd69b574255f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_04e3c2e2a52b4f08a170b6dcd83a86b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:02&lt;00:00, 67591043.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4d17e24dfb2449ca3daa53bc2f26102"
          }
        },
        "cc08c71f784e4a2a9eddeb2de95c8792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad662c6fcfad4fe2bbf4df8ef79bc73a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "176645ddbf0844aebed638f535015063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2324b127888048b7ae800836db3c3a99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04e3c2e2a52b4f08a170b6dcd83a86b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4d17e24dfb2449ca3daa53bc2f26102": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravraha/OpenPCDet/blob/master/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUSmrAuICx37"
      },
      "source": [
        "# !rm -rf images/\n",
        "!gdown --id 17l6H61tLAu26zGuei38r_T5ssjbYUeaJ -O - --quiet | tar --skip-old-files -zxf -"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYETVB_ZWtzb"
      },
      "source": [
        "## Gander"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning omegaconf"
      ],
      "metadata": {
        "id": "zyeMJb0uKFfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gander/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2Z-cmBcM305",
        "outputId": "a0c802cb-6b7f-45b4-8eed-2babf1f58efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gander\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gander.models import gan\n",
        "from omegaconf import OmegaConf"
      ],
      "metadata": {
        "id": "MqPvm1hAJtK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf = OmegaConf.load(\"config.yaml\")\n",
        "m = gan.GAN(conf)\n",
        "m"
      ],
      "metadata": {
        "id": "SHYCJjdaLdZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaNr1y58E5rE"
      },
      "source": [
        "!git config --global user.email \"souravraha@ufl.edu\"\n",
        "!git config --global user.name \"Sourav Raha\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iis9tcJeC12c",
        "outputId": "81ea9844-c372-4db0-cfd9-e4c50abd5c71"
      },
      "source": [
        "!git add -A\n",
        "!git commit -m 'can load numpy data'\n",
        "!git push origin lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[lightning 1485599] can load numpy data\n",
            " 2 files changed, 3 insertions(+), 2 deletions(-)\n",
            "Counting objects: 6, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (6/6), done.\n",
            "Writing objects: 100% (6/6), 539 bytes | 539.00 KiB/s, done.\n",
            "Total 6 (delta 4), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
            "To https://github.com/souravraha/pytorch_GAN_zoo.git\n",
            "   6ad9a8d..1485599  lightning -> lightning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETmq6yl7Yy_9"
      },
      "source": [
        "import torch\n",
        "\n",
        "start = torch.arange(1., 5.)\n",
        "end = torch.empty(4).fill_(10)\n",
        "start\n",
        "end\n",
        "torch.lerp(start, end, 0.5)\n",
        "torch.lerp(start, end, torch.full_like(start, 0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgeosqmQWtZU"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBTemasd-ta3"
      },
      "source": [
        "## Big GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxdXIhpp-suB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-LeBTcY69aY"
      },
      "source": [
        "## Facebook Zoo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhS_diWc7CM6",
        "outputId": "f3d46d76-da1a-4492-cefb-054c239d08f6"
      },
      "source": [
        "!git clone https://github.com/souravraha/pytorch_GAN_zoo.git\n",
        "%cd pytorch_GAN_zoo/\n",
        "!git remote add upstream https://github.com/facebookresearch/pytorch_GAN_zoo.git\n",
        "!git pull upstream master\n",
        "!git checkout lightning\n",
        "!git branch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch_GAN_zoo'...\n",
            "remote: Enumerating objects: 1565, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/70)\u001b[K\rremote: Counting objects:   2% (2/70)\u001b[K\rremote: Counting objects:   4% (3/70)\u001b[K\rremote: Counting objects:   5% (4/70)\u001b[K\rremote: Counting objects:   7% (5/70)\u001b[K\rremote: Counting objects:   8% (6/70)\u001b[K\rremote: Counting objects:  10% (7/70)\u001b[K\rremote: Counting objects:  11% (8/70)\u001b[K\rremote: Counting objects:  12% (9/70)\u001b[K\rremote: Counting objects:  14% (10/70)\u001b[K\rremote: Counting objects:  15% (11/70)\u001b[K\rremote: Counting objects:  17% (12/70)\u001b[K\rremote: Counting objects:  18% (13/70)\u001b[K\rremote: Counting objects:  20% (14/70)\u001b[K\rremote: Counting objects:  21% (15/70)\u001b[K\rremote: Counting objects:  22% (16/70)\u001b[K\rremote: Counting objects:  24% (17/70)\u001b[K\rremote: Counting objects:  25% (18/70)\u001b[K\rremote: Counting objects:  27% (19/70)\u001b[K\rremote: Counting objects:  28% (20/70)\u001b[K\rremote: Counting objects:  30% (21/70)\u001b[K\rremote: Counting objects:  31% (22/70)\u001b[K\rremote: Counting objects:  32% (23/70)\u001b[K\rremote: Counting objects:  34% (24/70)\u001b[K\rremote: Counting objects:  35% (25/70)\u001b[K\rremote: Counting objects:  37% (26/70)\u001b[K\rremote: Counting objects:  38% (27/70)\u001b[K\rremote: Counting objects:  40% (28/70)\u001b[K\rremote: Counting objects:  41% (29/70)\u001b[K\rremote: Counting objects:  42% (30/70)\u001b[K\rremote: Counting objects:  44% (31/70)\u001b[K\rremote: Counting objects:  45% (32/70)\u001b[K\rremote: Counting objects:  47% (33/70)\u001b[K\rremote: Counting objects:  48% (34/70)\u001b[K\rremote: Counting objects:  50% (35/70)\u001b[K\rremote: Counting objects:  51% (36/70)\u001b[K\rremote: Counting objects:  52% (37/70)\u001b[K\rremote: Counting objects:  54% (38/70)\u001b[K\rremote: Counting objects:  55% (39/70)\u001b[K\rremote: Counting objects:  57% (40/70)\u001b[K\rremote: Counting objects:  58% (41/70)\u001b[K\rremote: Counting objects:  60% (42/70)\u001b[K\rremote: Counting objects:  61% (43/70)\u001b[K\rremote: Counting objects:  62% (44/70)\u001b[K\rremote: Counting objects:  64% (45/70)\u001b[K\rremote: Counting objects:  65% (46/70)\u001b[K\rremote: Counting objects:  67% (47/70)\u001b[K\rremote: Counting objects:  68% (48/70)\u001b[K\rremote: Counting objects:  70% (49/70)\u001b[K\rremote: Counting objects:  71% (50/70)\u001b[K\rremote: Counting objects:  72% (51/70)\u001b[K\rremote: Counting objects:  74% (52/70)\u001b[K\rremote: Counting objects:  75% (53/70)\u001b[K\rremote: Counting objects:  77% (54/70)\u001b[K\rremote: Counting objects:  78% (55/70)\u001b[K\rremote: Counting objects:  80% (56/70)\u001b[K\rremote: Counting objects:  81% (57/70)\u001b[K\rremote: Counting objects:  82% (58/70)\u001b[K\rremote: Counting objects:  84% (59/70)\u001b[K\rremote: Counting objects:  85% (60/70)\u001b[K\rremote: Counting objects:  87% (61/70)\u001b[K\rremote: Counting objects:  88% (62/70)\u001b[K\rremote: Counting objects:  90% (63/70)\u001b[K\rremote: Counting objects:  91% (64/70)\u001b[K\rremote: Counting objects:  92% (65/70)\u001b[K\rremote: Counting objects:  94% (66/70)\u001b[K\rremote: Counting objects:  95% (67/70)\u001b[K\rremote: Counting objects:  97% (68/70)\u001b[K\rremote: Counting objects:  98% (69/70)\u001b[K\rremote: Counting objects: 100% (70/70)\u001b[K\rremote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 1565 (delta 34), reused 56 (delta 28), pack-reused 1495\u001b[K\n",
            "Receiving objects: 100% (1565/1565), 2.08 MiB | 18.88 MiB/s, done.\n",
            "Resolving deltas: 100% (994/994), done.\n",
            "/content/pytorch_GAN_zoo/pytorch_GAN_zoo\n",
            "fatal: Couldn't find remote ref master\n",
            "Branch 'lightning' set up to track remote branch 'lightning' from 'origin'.\n",
            "Switched to a new branch 'lightning'\n",
            "* \u001b[32mlightning\u001b[m\n",
            "  master\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.progressive_gan import ProgressiveGAN"
      ],
      "metadata": {
        "id": "YKKh8bWRorgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef8ajHdsI02W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e065decc-158e-45c8-a759-8c92f8c7dca6"
      },
      "source": [
        "%pip install -q -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 676 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 420 kB 47.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 249 kB 49.2 MB/s \n",
            "\u001b[?25h  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = ProgressiveGAN()"
      ],
      "metadata": {
        "id": "la6yeOEbpHgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m.netD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQe3BZY3pNCy",
        "outputId": "362e23a6-36fc-40ed-80e8-779749e9b604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DNet(\n",
              "  (scaleLayers): ModuleList()\n",
              "  (fromRGBLayers): ModuleList(\n",
              "    (0): EqualizedConv2d(\n",
              "      (module): Conv2d(3, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (mergeLayers): ModuleList()\n",
              "  (decisionLayer): EqualizedLinear(\n",
              "    (module): Linear(in_features=512, out_features=1, bias=True)\n",
              "  )\n",
              "  (groupScaleZero): ModuleList(\n",
              "    (0): EqualizedConv2d(\n",
              "      (module): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "    (1): EqualizedLinear(\n",
              "      (module): Linear(in_features=8192, out_features=512, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (leakyRelu): LeakyReLU(negative_slope=0.2)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGc--6i2-Ww-"
      },
      "source": [
        "import json\n",
        "\n",
        "dict = {\n",
        "    \"pathDB\": '/content/images/train/',\n",
        "    \"config\": {\n",
        "        \"dimOutput\": 1,\n",
        "        \"weightConditionG\": 1,\n",
        "        \"weightConditionD\": 1,\n",
        "    },\n",
        "    \"imagefolderDataset\": True,\n",
        "}\n",
        "\n",
        "with open(\"npyImageData.json\", \"w\") as outfile:\n",
        "    json.dump(dict, outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWOYAtqvEpS5",
        "outputId": "03af9e8c-b09b-4d35-fd3f-5f65621cdbf6"
      },
      "source": [
        "%cd pytorch_GAN_zoo/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch_GAN_zoo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_AWtdT6__MH",
        "outputId": "0f529bdf-0a80-42f2-ee00-637c4045f1d3"
      },
      "source": [
        "%run -i train.py PGAN -c npyImageData.json -n trial_00 --np_vis -s 5000 -d ../drive/MyDrive/Logs/F/FBPGAN/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running PGAN\n",
            "size 10\n",
            "75000 images found\n",
            "AC-GAN classes : \n",
            "{'Main': {'order': 0, 'values': ['vort', 'no', 'sphere']}}\n",
            "\n",
            "size 10\n",
            "75000 images found\n",
            "75000 images detected\n",
            "Model found at path ../drive/MyDrive/Logs/F/FBPGAN/trial_00/trial_00_s0_i5000.pt, pursuing the training\n",
            "Average network found !\n",
            "size (4, 4)\n",
            "75000 images found\n",
            "[0 :   5100] loss G : 1.741 loss D : 2.762\n",
            "[0 :   5200] loss G : 3.509 loss D : 2.358\n",
            "[0 :   5300] loss G : 4.427 loss D : 1.384\n",
            "[0 :   5400] loss G : 3.627 loss D : 1.750\n",
            "[0 :   5500] loss G : 1.296 loss D : 2.665\n",
            "[0 :   5600] loss G : 1.336 loss D : 1.983\n",
            "[0 :   5700] loss G : 3.105 loss D : 1.636\n",
            "[0 :   5800] loss G : 1.778 loss D : 2.355\n",
            "[0 :   5900] loss G : 1.843 loss D : 2.389\n",
            "[0 :   6000] loss G : 1.266 loss D : 1.902\n",
            "[0 :   6100] loss G : 2.748 loss D : 1.401\n",
            "[0 :   6200] loss G : 1.792 loss D : 2.770\n",
            "[0 :   6300] loss G : 2.203 loss D : 3.221\n",
            "[0 :   6400] loss G : 4.590 loss D : 1.363\n",
            "[0 :   6500] loss G : 2.980 loss D : 1.327\n",
            "[0 :   6600] loss G : 3.135 loss D : 2.585\n",
            "[0 :   6700] loss G : 0.038 loss D : 3.384\n",
            "[0 :   6800] loss G : 2.576 loss D : 1.155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "dI73Fr7LGvCW",
        "outputId": "1c740703-ec30-4bc6-cfa3-1df6e970691e"
      },
      "source": [
        "%run -i eval.py visualization -n trial_00 -m PGAN --np_vis --showLabels -d ../drive/MyDrive/Logs/F/FBPGAN/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running visualization\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/content/pytorch_GAN_zoo/eval.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-h'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--help'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'help'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualisation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvis_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pytorch_GAN_zoo/models/eval/visualization.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(parser, visualisation)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheckpointData\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         raise FileNotFoundError(\n\u001b[0;32m---> 70\u001b[0;31m             \"Not checkpoint found for model \" + name + \" at directory \" + dir)\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mmodelConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpointData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"builtin_function_or_method\") to str"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nBPqqqkHm1H"
      },
      "source": [
        "# Lightning Bolts Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVJUO2w8H4KC"
      },
      "source": [
        "!git clone https://souravraha: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@github.com/souravraha/lightning-bolts.git\n",
        "%cd lightning-bolts/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8TgSLsLKv26"
      },
      "source": [
        "# Ray Tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzTB69N3KvXq",
        "outputId": "055b8790-c19c-4d72-b439-6caf7b656013"
      },
      "source": [
        "!git clone https://souravraha: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@github.com/souravraha/ray.git\n",
        "%cd ray/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ray'...\n",
            "remote: Enumerating objects: 140501, done.\u001b[K\n",
            "remote: Counting objects: 100% (261/261), done.\u001b[K\n",
            "remote: Compressing objects: 100% (170/170), done.\u001b[K\n",
            "remote: Total 140501 (delta 116), reused 192 (delta 84), pack-reused 140240\u001b[K\n",
            "Receiving objects: 100% (140501/140501), 125.93 MiB | 21.17 MiB/s, done.\n",
            "Resolving deltas: 100% (103541/103541), done.\n",
            "/content/ray\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opMIF2uTPAfr",
        "outputId": "95d2a0b9-084f-44c5-b3f7-8df3178d3124"
      },
      "source": [
        "!git remote add upstream https://github.com/ray-project/ray.git\n",
        "!git remote -v\n",
        "!git pull upstream master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "origin\thttps://souravraha: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@github.com/souravraha/ray.git (fetch)\n",
            "origin\thttps://souravraha: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@github.com/souravraha/ray.git (push)\n",
            "upstream\thttps://github.com/ray-project/ray.git (fetch)\n",
            "upstream\thttps://github.com/ray-project/ray.git (push)\n",
            "remote: Enumerating objects: 534, done.\u001b[K\n",
            "remote: Counting objects: 100% (534/534), done.\u001b[K\n",
            "remote: Compressing objects: 100% (261/261), done.\u001b[K\n",
            "remote: Total 363 (delta 297), reused 153 (delta 100), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (363/363), 90.96 KiB | 18.19 MiB/s, done.\n",
            "Resolving deltas: 100% (297/297), completed with 158 local objects.\n",
            "From https://github.com/ray-project/ray\n",
            " * branch                master     -> FETCH_HEAD\n",
            " * [new branch]          master     -> upstream/master\n",
            "Updating 7c01ea7d2..d52ffd926\n",
            "Fast-forward\n",
            " README.rst                                         |  24 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
            " benchmarks/distributed/test_many_actors.py         |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " benchmarks/distributed/test_many_pgs.py            |   5 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " benchmarks/distributed/test_many_tasks.py          |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " deploy/charts/ray/templates/raycluster.yaml        |   6 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " deploy/charts/ray/values.yaml                      |   3 \u001b[31m-\u001b[m\n",
            " deploy/components/example_cluster.yaml             |   4 \u001b[31m-\u001b[m\n",
            " doc/source/cluster/config.rst                      |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " doc/source/data/dataset-pipeline.rst               |  17 \u001b[32m+++\u001b[m\n",
            " doc/source/getting-involved.rst                    |  31 \u001b[32m++++++\u001b[m\n",
            " doc/source/serve/ml-models.rst                     |   3 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/_private/log_monitor.py                 |  70 \u001b[32m+++++++++\u001b[m\u001b[31m---\u001b[m\n",
            " python/ray/_private/runtime_env.py                 |   9 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/_private/test_utils.py                  |  25 \u001b[32m+++++\u001b[m\n",
            " python/ray/_private/utils.py                       |   8 \u001b[32m++\u001b[m\n",
            " python/ray/_raylet.pyx                             |  16 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/actor.py                                |   6 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/autoscaler/_private/monitor.py          |   3 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/autoscaler/_private/util.py             |  27 \u001b[32m++\u001b[m\u001b[31m---\u001b[m\n",
            " python/ray/autoscaler/aliyun/defaults.yaml         |   6 \u001b[31m-\u001b[m\n",
            " python/ray/autoscaler/aliyun/example-full.yaml     |   6 \u001b[31m-\u001b[m\n",
            " python/ray/autoscaler/aliyun/example-linux.yaml    |   6 \u001b[31m-\u001b[m\n",
            " python/ray/autoscaler/aws/defaults.yaml            |   6 \u001b[31m-\u001b[m\n",
            " python/ray/autoscaler/aws/example-full.yaml        |   6 \u001b[31m-\u001b[m\n",
            " python/ray/autoscaler/aws/example-gpu-docker.yaml  |   6 \u001b[31m-\u001b[m\n",
            " .../autoscaler/aws/example-launch-templates.yaml   |   1 \u001b[31m-\u001b[m\n",
            " .../autoscaler/aws/example-network-interfaces.yaml |   1 \u001b[31m-\u001b[m\n",
            " python/ray/autoscaler/azure/defaults.yaml          |   7 \u001b[31m--\u001b[m\n",
            " python/ray/autoscaler/azure/example-full.yaml      |   6 \u001b[31m-\u001b[m\n",
            " .../ray/autoscaler/azure/example-gpu-docker.yaml   |   6 \u001b[31m-\u001b[m\n",
            " python/ray/autoscaler/gcp/defaults.yaml            |   6 \u001b[31m-\u001b[m\n",
            " python/ray/autoscaler/gcp/example-full.yaml        |   6 \u001b[31m-\u001b[m\n",
            " python/ray/autoscaler/gcp/example-gpu-docker.yaml  |   6 \u001b[31m-\u001b[m\n",
            " python/ray/autoscaler/gcp/tpu.yaml                 |   2 \u001b[31m-\u001b[m\n",
            " python/ray/autoscaler/kubernetes/defaults.yaml     |   6 \u001b[31m-\u001b[m\n",
            " python/ray/autoscaler/kubernetes/example-full.yaml |   6 \u001b[31m-\u001b[m\n",
            " python/ray/data/block.py                           |   2 \u001b[32m+\u001b[m\n",
            " python/ray/data/dataset_pipeline.py                |   1 \u001b[31m-\u001b[m\n",
            " python/ray/data/datasource/datasource.py           |   2 \u001b[32m+\u001b[m\n",
            " .../ray/data/datasource/file_based_datasource.py   |   2 \u001b[32m+\u001b[m\n",
            " python/ray/data/datasource/parquet_datasource.py   |  19 \u001b[32m+++\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/data/impl/util.py                       |  31 \u001b[32m++++++\u001b[m\n",
            " python/ray/data/tests/test_dataset.py              |  63 \u001b[32m+++++++++\u001b[m\u001b[31m--\u001b[m\n",
            " python/ray/experimental/workflow/api.py            |  13 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/experimental/workflow/api.pyi           |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/experimental/workflow/common.py         |  35 \u001b[32m+++++\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/experimental/workflow/execution.py      |  42 \u001b[32m++++\u001b[m\u001b[31m---\u001b[m\n",
            " python/ray/experimental/workflow/step_executor.py  |  18 \u001b[32m+\u001b[m\u001b[31m--\u001b[m\n",
            " python/ray/experimental/workflow/step_function.py  |  10 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " .../workflow/tests/test_basic_workflows.py         |   3 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " .../workflow/tests/test_basic_workflows_2.py       | 110 \u001b[32m+++++++++++++++++++\u001b[m\n",
            " .../workflow/tests/test_dynamic_workflow_ref.py    |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " .../experimental/workflow/virtual_actor_class.py   |   1 \u001b[32m+\u001b[m\n",
            " .../ray/experimental/workflow/workflow_access.py   |  81 \u001b[32m++++++++++\u001b[m\u001b[31m----\u001b[m\n",
            " .../ray/experimental/workflow/workflow_context.py  |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " .../ray/experimental/workflow/workflow_storage.py  |  28 \u001b[32m++++\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/external_storage.py                     |   7 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/ray_constants.py                        |   7 \u001b[32m++\u001b[m\n",
            " python/ray/serve/BUILD                             |   1 \u001b[32m+\u001b[m\n",
            " python/ray/serve/__init__.py                       |   5 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/serve/common.py                         |   1 \u001b[31m-\u001b[m\n",
            " python/ray/serve/constants.py                      |   7 \u001b[31m--\u001b[m\n",
            " python/ray/serve/controller.py                     |   5 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/serve/endpoint_state.py                 |   1 \u001b[31m-\u001b[m\n",
            " python/ray/serve/http_proxy.py                     |  23 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
            " python/ray/serve/http_util.py                      |   1 \u001b[32m+\u001b[m\n",
            " .../ray/serve/tests/test_http_prefix_matching.py   |  70 \u001b[32m+++++\u001b[m\u001b[31m-------\u001b[m\n",
            " python/ray/serve/tests/test_http_routes.py         |  15 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/serve/tests/test_standalone.py          |   1 \u001b[32m+\u001b[m\n",
            " python/ray/serve/utils.py                          |  74 \u001b[32m+\u001b[m\u001b[31m------------\u001b[m\n",
            " python/ray/tests/test_actor_advanced.py            |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tests/test_autoscaler.py                |  10 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tests/test_autoscaler_yaml.py           |   6 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tests/test_cli.py                       |  30 \u001b[31m-----\u001b[m\n",
            " .../test_ray_up_no_max_worker.txt                  |  53 \u001b[31m---------\u001b[m\n",
            " python/ray/tests/test_client_references.py         |   8 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tests/test_job.py                       |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tests/test_logging.py                   |  46 \u001b[32m+++++++\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tests/test_multi_node.py                |   6 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tests/test_multi_node_3.py              |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tests/test_namespace.py                 |  38 \u001b[32m++++++\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tests/test_output.py                    |  71 \u001b[32m+++++++++++\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tests/test_placement_group.py           |  12 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tests/test_reference_counting_2.py      |  10 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tests/test_runtime_env.py               |  45 \u001b[32m++++++++\u001b[m\n",
            " python/ray/tune/session.py                         |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tune/suggest/hyperopt.py                |   5 \u001b[32m+\u001b[m\n",
            " python/ray/tune/suggest/variant_generator.py       |  16 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tune/tests/test_sample.py               |  80 \u001b[32m++++++++++++++\u001b[m\n",
            " python/ray/tune/tune.py                            |  21 \u001b[32m+++\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/tune/utils/util.py                      |  35 \u001b[32m++++\u001b[m\u001b[31m--\u001b[m\n",
            " python/ray/util/annotations.py                     |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/util/client/__init__.py                 |   3 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/util/client/server/proxier.py           |   6 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " python/ray/worker.py                               | 107 \u001b[32m+++++++++++\u001b[m\u001b[31m-------\u001b[m\n",
            " .../{sclability => scalability}/object_store.txt   |   0\n",
            " .../{sclability => scalability}/single_node.txt    |   0\n",
            " .../release_logs/1.6.0/benchmarks/many_actors.txt  |   1 \u001b[32m+\u001b[m\n",
            " .../release_logs/1.6.0/benchmarks/many_nodes.txt   |   1 \u001b[32m+\u001b[m\n",
            " release/release_logs/1.6.0/benchmarks/many_pgs.txt |   1 \u001b[32m+\u001b[m\n",
            " release/release_logs/1.6.0/microbenchmark.txt      |  28 \u001b[32m+++++\u001b[m\n",
            " .../1.6.0/scalability/object_store.txt             |   1 \u001b[32m+\u001b[m\n",
            " .../release_logs/1.6.0/scalability/single_node.txt |  23 \u001b[32m++++\u001b[m\n",
            " .../1.6.0/stress_tests/dead_actors.txt             |  50 \u001b[32m+++++++++\u001b[m\n",
            " .../release_logs/1.6.0/stress_tests/many_tasks.txt |  50 \u001b[32m+++++++++\u001b[m\n",
            " .../1.6.0/stress_tests/placement_group.txt         |  50 \u001b[32m+++++++++\u001b[m\n",
            " release/rllib_tests/app_config.yaml                |   2 \u001b[32m+\u001b[m\n",
            " .../learning_tests/hard_learning_tests.yaml        |  93 \u001b[32m++++++++\u001b[m\u001b[31m--------\u001b[m\n",
            " .../workloads/multi_deployment_1k_noop_replica.py  |  13 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
            " .../workloads/single_deployment_1k_noop_replica.py |   7 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " rllib/evaluation/rollout_worker.py                 | 122 \u001b[32m++++++++++++++\u001b[m\u001b[31m-------\u001b[m\n",
            " rllib/evaluation/tests/test_rollout_worker.py      |  11 \u001b[32m++\u001b[m\n",
            " rllib/examples/deterministic_training.py           |   2 \u001b[32m+\u001b[m\n",
            " rllib/examples/env/env_using_remote_actor.py       |  20 \u001b[32m+++\u001b[m\u001b[31m-\u001b[m\n",
            " rllib/examples/env/mock_env.py                     |   4 \u001b[32m+\u001b[m\n",
            " rllib/models/tf/fcnet.py                           |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " .../debug_learning_failure_git_bisect.py           |  65 \u001b[32m+++++++\u001b[m\u001b[31m----\u001b[m\n",
            " rllib/tuned_examples/ddpg/halfcheetah-ddpg.yaml    |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " .../ddpg/halfcheetah-pybullet-ddpg.yaml            |  42 \u001b[32m+++++++\u001b[m\n",
            " .../tuned_examples/ddpg/hopper-pybullet-ddpg.yaml  |  44 \u001b[32m++++++++\u001b[m\n",
            " src/ray/gcs/gcs_server/gcs_actor_manager.cc        |   4 \u001b[32m+\u001b[m\n",
            " .../gcs/gcs_server/gcs_placement_group_manager.cc  |   2 \u001b[32m+\u001b[m\n",
            " src/ray/object_manager/object_manager.cc           |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " src/ray/object_manager/plasma/store.cc             |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " src/ray/object_manager/pull_manager.cc             |  11 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " src/ray/object_manager/pull_manager.h              |   7 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " src/ray/object_manager/test/pull_manager_test.cc   |  18 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
            " src/ray/raylet/local_object_manager.cc             |  94 \u001b[32m+++++++\u001b[m\u001b[31m---------\u001b[m\n",
            " src/ray/raylet/local_object_manager.h              |  27 \u001b[32m++\u001b[m\u001b[31m---\u001b[m\n",
            " src/ray/raylet/node_manager.cc                     |   6 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " src/ray/raylet/test/local_object_manager_test.cc   |  62 \u001b[32m++++++\u001b[m\u001b[31m-----\u001b[m\n",
            " 131 files changed, 1738 insertions(+), 800 deletions(-)\n",
            " create mode 100644 python/ray/data/impl/util.py\n",
            " delete mode 100644 python/ray/tests/test_cli_patterns/test_ray_up_no_max_worker.txt\n",
            " rename release/release_logs/1.5.0/{sclability => scalability}/object_store.txt (100%)\n",
            " rename release/release_logs/1.5.0/{sclability => scalability}/single_node.txt (100%)\n",
            " create mode 100644 release/release_logs/1.6.0/benchmarks/many_actors.txt\n",
            " create mode 100644 release/release_logs/1.6.0/benchmarks/many_nodes.txt\n",
            " create mode 100644 release/release_logs/1.6.0/benchmarks/many_pgs.txt\n",
            " create mode 100644 release/release_logs/1.6.0/microbenchmark.txt\n",
            " create mode 100644 release/release_logs/1.6.0/scalability/object_store.txt\n",
            " create mode 100644 release/release_logs/1.6.0/scalability/single_node.txt\n",
            " create mode 100644 release/release_logs/1.6.0/stress_tests/dead_actors.txt\n",
            " create mode 100644 release/release_logs/1.6.0/stress_tests/many_tasks.txt\n",
            " create mode 100644 release/release_logs/1.6.0/stress_tests/placement_group.txt\n",
            " create mode 100644 rllib/tuned_examples/ddpg/halfcheetah-pybullet-ddpg.yaml\n",
            " create mode 100644 rllib/tuned_examples/ddpg/hopper-pybullet-ddpg.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl7pCKEhPZvv",
        "outputId": "1995adcf-dde4-478b-e019-cbde393e8f81"
      },
      "source": [
        "!git checkout pl-issues\n",
        "!git branch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Branch 'pl-issues' set up to track remote branch 'pl-issues' from 'origin'.\n",
            "Switched to a new branch 'pl-issues'\n",
            "  master\u001b[m\n",
            "* \u001b[32mpl-issues\u001b[m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6axbzhrao9N"
      },
      "source": [
        "!git config --global user.email \"souravraha@ufl.edu\"\n",
        "!git config --global user.name \"souravraha\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIFMP-99aGjX",
        "outputId": "d616ea1c-d40f-457e-aa2d-50d138d6a2a5"
      },
      "source": [
        "!git add -A\n",
        "!git commit -m \"this doesn't work, creates duplicate in auroc\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[pl-issues f608cf46d] this doesn't work, creates duplicate in auroc\n",
            " 1 file changed, 21 insertions(+), 19 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSlcAH_ha-FP",
        "outputId": "5856cf36-e7a0-4ef5-88e6-853e20e411e9"
      },
      "source": [
        "!git push origin pl-issues"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting objects: 7, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects:  14% (1/7)   \rCompressing objects:  28% (2/7)   \rCompressing objects:  42% (3/7)   \rCompressing objects:  57% (4/7)   \rCompressing objects:  71% (5/7)   \rCompressing objects:  85% (6/7)   \rCompressing objects: 100% (7/7)   \rCompressing objects: 100% (7/7), done.\n",
            "Writing objects:  14% (1/7)   \rWriting objects:  28% (2/7)   \rWriting objects:  42% (3/7)   \rWriting objects:  57% (4/7)   \rWriting objects:  71% (5/7)   \rWriting objects:  85% (6/7)   \rWriting objects: 100% (7/7)   \rWriting objects: 100% (7/7), 757 bytes | 757.00 KiB/s, done.\n",
            "Total 7 (delta 6), reused 0 (delta 0)\n",
            "remote: Resolving deltas:   0% (0/6)\u001b[K\rremote: Resolving deltas:  16% (1/6)\u001b[K\rremote: Resolving deltas:  33% (2/6)\u001b[K\rremote: Resolving deltas:  50% (3/6)\u001b[K\rremote: Resolving deltas:  66% (4/6)\u001b[K\rremote: Resolving deltas:  83% (5/6)\u001b[K\rremote: Resolving deltas: 100% (6/6)\u001b[K\rremote: Resolving deltas: 100% (6/6), completed with 6 local objects.\u001b[K\n",
            "To https://github.com/souravraha/ray.git\n",
            "   8ee283c63..f608cf46d  pl-issues -> pl-issues\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4cSfGBPBLpR",
        "outputId": "0d00c2f5-b737-4a60-b6ae-c8454b5d6a63"
      },
      "source": [
        "metrics = tm.MetricCollection(\n",
        "    [   \n",
        "        tm.Accuracy(num_classes=10),\n",
        "        tm.AUROC(num_classes=10),\n",
        "    ]\n",
        ")\n",
        "train_metrics = metrics.clone(prefix=\"ptl/train_\")\n",
        "val_metrics = metrics.clone(prefix=\"ptl/val_\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiUrpFvbBlha",
        "outputId": "76affc05-7d08-450f-837d-ed6ff01051a2"
      },
      "source": [
        "val_metrics.add_metrics(tm.ROC(num_classes=10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `ROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esZQv2Y-qK91"
      },
      "source": [
        "# flake8: noqa\n",
        "# yapf: disable\n",
        "\n",
        "# __import_lightning_begin__\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from filelock import FileLock\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import torchmetrics as tm\n",
        "import os\n",
        "# __import_lightning_end__\n",
        "\n",
        "# __import_tune_begin__\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.utilities.cloud_io import load as pl_load\n",
        "from ray import tune\n",
        "from ray.tune import JupyterNotebookReporter\n",
        "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
        "from ray.tune.integration.pytorch_lightning import TuneReportCallback, \\\n",
        "    TuneReportCheckpointCallback\n",
        "# __import_tune_end__\n",
        "\n",
        "\n",
        "# __lightning_begin__\n",
        "class LightningMNISTClassifier(pl.LightningModule):\n",
        "    \"\"\"\n",
        "    This has been adapted from\n",
        "    https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, data_dir=None):\n",
        "        super(LightningMNISTClassifier, self).__init__()\n",
        "\n",
        "        self.data_dir = data_dir or os.getcwd()\n",
        "\n",
        "        self.layer_1_size = config[\"layer_1_size\"]\n",
        "        self.layer_2_size = config[\"layer_2_size\"]\n",
        "        self.lr = config[\"lr\"]\n",
        "        self.batch_size = config[\"batch_size\"]\n",
        "\n",
        "        # mnist images are (1, 28, 28) (channels, width, height)\n",
        "        self.layer_1 = torch.nn.Linear(28 * 28, self.layer_1_size)\n",
        "        self.layer_2 = torch.nn.Linear(self.layer_1_size, self.layer_2_size)\n",
        "        self.layer_3 = torch.nn.Linear(self.layer_2_size, 10)\n",
        "\n",
        "        metrics = tm.MetricCollection(\n",
        "            [   \n",
        "                tm.Accuracy(num_classes=self.layer_3.out_features),\n",
        "                tm.AUROC(num_classes=self.layer_3.out_features, compute_on_step=False),\n",
        "            ]\n",
        "        )\n",
        "        self.train_metrics = metrics.clone(prefix=\"ptl/train_\")\n",
        "        self.val_metrics = metrics.clone(prefix=\"ptl/val_\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, channels, width, height = x.size()\n",
        "        x = x.view(batch_size, -1)\n",
        "\n",
        "        x = self.layer_1(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.layer_2(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.layer_3(x)\n",
        "        x = torch.log_softmax(x, dim=1)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def cross_entropy_loss(self, logits, labels):\n",
        "        return F.nll_loss(logits, labels)\n",
        "\n",
        "    def accuracy(self, logits, labels):\n",
        "        _, predicted = torch.max(logits.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        accuracy = correct / len(labels)\n",
        "        return torch.tensor(accuracy)\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        x, y = train_batch\n",
        "        logits = self(x)\n",
        "        # loss = self.cross_entropy_loss(logits, y)\n",
        "        # accuracy = self.accuracy(logits, y)\n",
        "\n",
        "        # self.log(\"ptl/train_loss\", loss)\n",
        "        # self.log(\"ptl/train_accuracy\", accuracy)\n",
        "        if batch_idx % 110 == 0:\n",
        "            print('train',len(self.train_metrics.AUROC.target), \n",
        "            [getattr(self.train_metrics.Accuracy, i).item() for i in ['fp', 'fn', 'tp', 'tn']])\n",
        "        # Turns out one has to manually call reset on MetricCollections:\n",
        "        # https://github.com/PyTorchLightning/pytorch-lightning/issues/6201\n",
        "\n",
        "        # self.train_metrics.update(F.softmax(logits, 1), y)\n",
        "        \n",
        "        try:\n",
        "            Dict = self.train_metrics(F.softmax(logits, 1), y)      #self.train_metrics.compute()\n",
        "        except Exception as error:\n",
        "            if hasattr(self, 'batch') and batch_idx == self.batch:\n",
        "                print('train', batch_idx, self.global_step, self.train_metrics.AUROC.target, \n",
        "                # [getattr(self.train_metrics.Accuracy, i).item() for i in ['fp', 'fn', 'tp', 'tn']]\n",
        "                )\n",
        "                del self.batch\n",
        "            print(error)\n",
        "            print(batch_idx, self.train_metrics.AUROC.target, \n",
        "            [getattr(self.train_metrics.Accuracy, i).item() for i in ['fp', 'fn', 'tp', 'tn']])\n",
        "            self.batch = batch_idx + 1\n",
        "            Dict = \n",
        "        #     pass\n",
        "        else:\n",
        "            if hasattr(self, 'batch') and batch_idx == self.batch:\n",
        "                print('train', batch_idx, self.global_step, self.train_metrics.AUROC.target, \n",
        "                # [getattr(self.train_metrics.Accuracy, i).item() for i in ['fp', 'fn', 'tp', 'tn']]\n",
        "                )\n",
        "                del self.batch\n",
        "        #     self.log_dict(self.train_metrics, on_epoch=True)\n",
        "        finally:\n",
        "            Dict[\"ptl/train_loss\"] = self.cross_entropy_loss(logits, y)\n",
        "            self.log_dict()\n",
        "            return Dict[\"ptl/train_loss\"]\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        x, y = val_batch\n",
        "        logits = self(x)\n",
        "        # loss = self.cross_entropy_loss(logits, y)\n",
        "        # accuracy = self.accuracy(logits, y)\n",
        "\n",
        "        # self.log(\"ptl/val_loss\", loss)\n",
        "        # self.log(\"ptl/val_Accuracy\", accuracy)\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('val', len(self.val_metrics.AUROC.target), \n",
        "            [getattr(self.val_metrics.Accuracy, i).item() for i in ['fp', 'fn', 'tp', 'tn']])\n",
        "        \n",
        "        self.val_metrics.update(F.softmax(logits, 1), y)\n",
        "        try:\n",
        "            Dict = self.val_metrics.compute()   #self.val_metrics(F.softmax(logits, 1), y)\n",
        "        except Exception as error:\n",
        "            print(error)\n",
        "            print(batch_idx, self.val_metrics.AUROC.target, \n",
        "            [getattr(self.val_metrics.Accuracy, i).item() for i in ['fp', 'fn', 'tp', 'tn']])\n",
        "            # Dict = {}\n",
        "            # pass\n",
        "        else:\n",
        "            self.log_dict(self.val_metrics)\n",
        "        finally:\n",
        "            # Dict[\"ptl/val_loss\"] = self.cross_entropy_loss(logits, y)\n",
        "            self.log(\"ptl/val_loss\", self.cross_entropy_loss(logits, y))\n",
        "\n",
        "    # def validation_epoch_end(self, outputs):\n",
        "        # avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "        # avg_acc = torch.stack([x[\"val_Accuracy\"] for x in outputs]).mean()\n",
        "        # self.log(\"ptl/val_loss\", avg_loss)\n",
        "        # self.log(\"ptl/val_Accuracy\", avg_acc)\n",
        "\n",
        "    @staticmethod\n",
        "    def download_data(data_dir):\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307, ), (0.3081, ))\n",
        "        ])\n",
        "        with FileLock(os.path.expanduser(\"~/.data.lock\")):\n",
        "            return MNIST(data_dir, train=True, download=True, transform=transform)\n",
        "\n",
        "    def prepare_data(self):\n",
        "        mnist_train = self.download_data(self.data_dir)\n",
        "\n",
        "        self.mnist_train, self.mnist_val = random_split(\n",
        "            mnist_train, [55000, 5000])\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.mnist_train, batch_size=int(self.batch_size))\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.mnist_val, batch_size=int(self.batch_size))\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        return optimizer\n",
        "\n",
        "\n",
        "def train_mnist(config):\n",
        "    model = LightningMNISTClassifier(config)\n",
        "    \n",
        "    trainer = pl.Trainer(max_epochs=10, show_progress_bar=False)\n",
        "\n",
        "    trainer.fit(model)\n",
        "# __lightning_end__\n",
        "\n",
        "\n",
        "# __tune_train_begin__\n",
        "def train_mnist_tune(config, num_epochs=10, num_gpus=0):\n",
        "    data_dir = os.path.expanduser(\"~/data\")\n",
        "    kwargs = {\n",
        "        # \"num_sanity_val_steps\": 0,\n",
        "        \"limit_train_batches\": 0.2,\n",
        "        \"limit_val_batches\": 0.2,\n",
        "        \"max_epochs\": num_epochs,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        \"gpus\": math.ceil(num_gpus),\n",
        "        \"logger\": TensorBoardLogger(\n",
        "            save_dir=tune.get_trial_dir(), name=\"\", version=\".\"),\n",
        "        \"progress_bar_refresh_rate\": 0,\n",
        "        \"callbacks\": [\n",
        "            TuneReportCallback(\n",
        "                metrics={\n",
        "                    \"loss\": \"ptl/val_loss\",\n",
        "                    \"mean_accuracy\": \"ptl/val_Accuracy\",\n",
        "                    \"auroc\": \"ptl/val_AUROC\"\n",
        "                },\n",
        "                on=\"validation_end\")\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    model = LightningMNISTClassifier(config=config, data_dir=data_dir)\n",
        "    trainer = pl.Trainer(**kwargs)\n",
        "\n",
        "    trainer.fit(model)\n",
        "# __tune_train_end__\n",
        "\n",
        "\n",
        "# __tune_train_checkpoint_begin__\n",
        "def train_mnist_tune_checkpoint(config,\n",
        "                                checkpoint_dir=None,\n",
        "                                num_epochs=10,\n",
        "                                num_gpus=0):\n",
        "    data_dir = os.path.expanduser(\"~/data\")\n",
        "    kwargs = {\n",
        "        # \"num_sanity_val_steps\": 0,\n",
        "        \"limit_train_batches\": 0.2,\n",
        "        \"limit_val_batches\": 0.2,\n",
        "        \"max_epochs\": num_epochs,\n",
        "        # If fractional GPUs passed in, convert to int.\n",
        "        \"gpus\": math.ceil(num_gpus),\n",
        "        \"logger\": TensorBoardLogger(\n",
        "            save_dir=tune.get_trial_dir(), name=\"\", version=\".\"),\n",
        "        \"progress_bar_refresh_rate\": 0,\n",
        "        \"callbacks\": [\n",
        "            TuneReportCheckpointCallback(\n",
        "                metrics={\n",
        "                    \"loss\": \"ptl/val_loss\",\n",
        "                    \"mean_accuracy\": \"ptl/val_Accuracy\",\n",
        "                    \"auroc\": \"ptl/val_AUROC\"\n",
        "                },\n",
        "                filename=\"checkpoint\",\n",
        "                on=\"validation_end\")\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    if checkpoint_dir:\n",
        "        kwargs[\"resume_from_checkpoint\"] = os.path.join(\n",
        "            checkpoint_dir, \"checkpoint\")\n",
        "\n",
        "    model = LightningMNISTClassifier(config=config, data_dir=data_dir)\n",
        "    trainer = pl.Trainer(**kwargs)\n",
        "\n",
        "    trainer.fit(model)\n",
        "# __tune_train_checkpoint_end__\n",
        "\n",
        "\n",
        "# __tune_asha_begin__\n",
        "def tune_mnist_asha(num_samples=10, num_epochs=10, gpus_per_trial=0):\n",
        "    config = {\n",
        "        \"layer_1_size\": tune.choice([32, 64, 128]),\n",
        "        \"layer_2_size\": tune.choice([64, 128, 256]),\n",
        "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
        "        \"batch_size\": tune.choice([8]),\n",
        "    }\n",
        "\n",
        "    scheduler = ASHAScheduler(\n",
        "        max_t=num_epochs,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "\n",
        "    reporter = JupyterNotebookReporter(\n",
        "        overwrite=False,\n",
        "        parameter_columns=[\"layer_1_size\", \"layer_2_size\", \"lr\", \"batch_size\"],\n",
        "        metric_columns=[\"auroc\", \"loss\", \"mean_accuracy\", \"training_iteration\"])\n",
        "\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_mnist_tune,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial),\n",
        "        resources_per_trial={\n",
        "            \"cpu\": 1,\n",
        "            \"gpu\": gpus_per_trial\n",
        "        },\n",
        "        metric=\"auroc\",\n",
        "        mode=\"max\",\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter,\n",
        "        fail_fast=True,\n",
        "        name=\"tune_mnist_asha\")\n",
        "\n",
        "    print(\"Best hyperparameters found were: \", analysis.best_config)\n",
        "\n",
        "# __tune_asha_end__\n",
        "\n",
        "\n",
        "# __tune_pbt_begin__\n",
        "def tune_mnist_pbt(num_samples=10, num_epochs=10, gpus_per_trial=0):\n",
        "    config = {\n",
        "        \"layer_1_size\": tune.choice([32, 64, 128]),\n",
        "        \"layer_2_size\": tune.choice([64, 128, 256]),\n",
        "        \"lr\": 1e-3,\n",
        "        \"batch_size\": 8,\n",
        "    }\n",
        "\n",
        "    scheduler = PopulationBasedTraining(\n",
        "        perturbation_interval=4,\n",
        "        hyperparam_mutations={\n",
        "            \"lr\": tune.loguniform(1e-4, 1e-1),\n",
        "            \"batch_size\": [8, 16, 32, 64, 128]\n",
        "        })\n",
        "\n",
        "    reporter = JupyterNotebookReporter(\n",
        "        overwrite=False,\n",
        "        parameter_columns=[\"layer_1_size\", \"layer_2_size\", \"lr\", \"batch_size\"],\n",
        "        metric_columns=[\"auroc\", \"loss\", \"mean_accuracy\", \"training_iteration\"])\n",
        "\n",
        "    analysis = tune.run(\n",
        "        tune.with_parameters(\n",
        "            train_mnist_tune_checkpoint,\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=gpus_per_trial),\n",
        "        resources_per_trial={\n",
        "            \"cpu\": 1,\n",
        "            \"gpu\": gpus_per_trial\n",
        "        },\n",
        "        metric=\"auroc\",\n",
        "        mode=\"max\",\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter,\n",
        "        fail_fast=True,\n",
        "        name=\"tune_mnist_pbt\")\n",
        "\n",
        "    print(\"Best hyperparameters found were: \", analysis.best_config)\n",
        "\n",
        "# __tune_pbt_end__\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        \"--smoke-test\", action=\"store_true\", help=\"Finish quickly for testing\")\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    if args.smoke_test:\n",
        "        tune_mnist_asha(num_samples=1, num_epochs=2, gpus_per_trial=0)\n",
        "        tune_mnist_pbt(num_samples=1, num_epochs=2, gpus_per_trial=0)\n",
        "    else:\n",
        "        # ASHA scheduler\n",
        "        tune_mnist_asha(num_samples=10, num_epochs=10, gpus_per_trial=0)\n",
        "        # Population based training\n",
        "        tune_mnist_pbt(num_samples=10, num_epochs=10, gpus_per_trial=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wP4V6X-VPn7N",
        "outputId": "c7cd760f-691a-4e61-9bea-b3de63235a40"
      },
      "source": [
        "%run -i /content/ray/python/ray/tune/examples/mnist_pytorch_lightning.py --smoke-test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 1.1/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 2.000: None | Iter 1.000: None<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/tune_mnist_asha<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  layer_1_size</th><th style=\"text-align: right;\">  layer_2_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_tune_25513_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">0.000354834</td><td style=\"text-align: right;\">           8</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   warnings.warn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m GPU available: False, used: False\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m /usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m \n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   | Name          | Type             | Params\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m ---------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m 0 | layer_1       | Linear           | 100 K \n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m 1 | layer_2       | Linear           | 8.3 K \n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m 2 | layer_3       | Linear           | 650   \n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m 3 | train_metrics | MetricCollection | 0     \n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m 4 | val_metrics   | MetricCollection | 0     \n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m ---------------------------------------------------\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m 109 K     Trainable params\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m 0         Non-trainable params\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m 109 K     Total params\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m 0.438     Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/deprecated_api.py:26: LightningDeprecationWarning: `Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   \"`Trainer.running_sanity_check` has been renamed to `Trainer.sanity_checking` and will be removed in v1.5.\"\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m 2021-08-27 02:04:48,546\tERROR function_runner.py:266 -- Runner Thread raised error.\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 260, in run\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 329, in entrypoint\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 594, in _trainable_func\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 353, in _inner\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     inner(config, checkpoint_dir=None)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 344, in inner\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/content/ray/python/ray/tune/examples/mnist_pytorch_lightning.py\", line 222, in train_mnist_tune\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     trainer.fit(model)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 553, in fit\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self._run(model)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 918, in _run\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _dispatch\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.accelerator.start_training(self)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.training_type_plugin.start_training(trainer)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in start_training\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 996, in run_stage\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1045, in _run_train\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.fit_loop.run()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     epoch_output = self.epoch_loop.run(train_dataloader)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 130, in advance\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     batch_output = self.batch_loop.run(batch, self.iteration_count, self._dataloader_idx)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 101, in run\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     super().run(batch, batch_idx, dataloader_idx)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 148, in advance\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     result = self._run_optimization(batch_idx, split_batch, opt_idx, optimizer)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 202, in _run_optimization\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 404, in _optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     using_lbfgs=is_lbfgs,\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 1618, in optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     optimizer.step(closure=optimizer_closure)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 209, in step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.__optimizer_step(*args, closure=closure, profiler_name=profiler_name, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 129, in __optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     trainer.accelerator.optimizer_step(optimizer, self._optimizer_idx, lambda_closure=closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 296, in optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.run_optimizer_step(optimizer, opt_idx, lambda_closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 303, in run_optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.training_type_plugin.optimizer_step(optimizer, lambda_closure=lambda_closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 226, in optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     optimizer.step(closure=lambda_closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     return func(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     return func(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\", line 66, in step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     loss = closure()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 236, in _training_step_and_backward_closure\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     result = self.training_step_and_backward(split_batch, batch_idx, opt_idx, optimizer, hiddens)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 537, in training_step_and_backward\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     result = self._training_step(split_batch, batch_idx, opt_idx, hiddens)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 307, in _training_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     training_step_output = self.trainer.accelerator.training_step(step_kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 193, in training_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     return self.training_type_plugin.training_step(*step_kwargs.values())\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 172, in training_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     return self.model.training_step(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/content/ray/python/ray/tune/examples/mnist_pytorch_lightning.py\", line 124, in training_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.log_dict({k: v for k, v in Dict.items() if v is not None})\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 521, in log_dict\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     add_dataloader_idx=add_dataloader_idx,\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 400, in log\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     value, object, self.__check_allowed, name, value, wrong_dtype=(numbers.Number, Metric, Tensor, dict)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/apply_func.py\", line 96, in apply_to_collection\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     return function(data, *args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 533, in __check_allowed\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     raise ValueError(f\"`self.log({name}, {value})` was called, but `{type(v).__name__}` values cannot be logged\")\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m ValueError: `self.log(ptl/train_AUROC, None)` was called, but `NoneType` values cannot be logged\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m Exception in thread Thread-2:\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.run()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 279, in run\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     raise e\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 260, in run\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 329, in entrypoint\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 594, in _trainable_func\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 353, in _inner\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     inner(config, checkpoint_dir=None)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 344, in inner\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/content/ray/python/ray/tune/examples/mnist_pytorch_lightning.py\", line 222, in train_mnist_tune\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     trainer.fit(model)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 553, in fit\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self._run(model)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 918, in _run\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _dispatch\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.accelerator.start_training(self)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.training_type_plugin.start_training(trainer)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in start_training\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 996, in run_stage\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1045, in _run_train\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.fit_loop.run()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     epoch_output = self.epoch_loop.run(train_dataloader)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 130, in advance\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     batch_output = self.batch_loop.run(batch, self.iteration_count, self._dataloader_idx)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 101, in run\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     super().run(batch, batch_idx, dataloader_idx)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 148, in advance\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     result = self._run_optimization(batch_idx, split_batch, opt_idx, optimizer)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 202, in _run_optimization\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 404, in _optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     using_lbfgs=is_lbfgs,\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 1618, in optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     optimizer.step(closure=optimizer_closure)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 209, in step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.__optimizer_step(*args, closure=closure, profiler_name=profiler_name, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 129, in __optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     trainer.accelerator.optimizer_step(optimizer, self._optimizer_idx, lambda_closure=closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 296, in optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.run_optimizer_step(optimizer, opt_idx, lambda_closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 303, in run_optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.training_type_plugin.optimizer_step(optimizer, lambda_closure=lambda_closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 226, in optimizer_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     optimizer.step(closure=lambda_closure, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     return func(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     return func(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\", line 66, in step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     loss = closure()\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 236, in _training_step_and_backward_closure\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     result = self.training_step_and_backward(split_batch, batch_idx, opt_idx, optimizer, hiddens)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 537, in training_step_and_backward\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     result = self._training_step(split_batch, batch_idx, opt_idx, hiddens)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 307, in _training_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     training_step_output = self.trainer.accelerator.training_step(step_kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 193, in training_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     return self.training_type_plugin.training_step(*step_kwargs.values())\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 172, in training_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     return self.model.training_step(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/content/ray/python/ray/tune/examples/mnist_pytorch_lightning.py\", line 124, in training_step\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     self.log_dict({k: v for k, v in Dict.items() if v is not None})\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 521, in log_dict\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     add_dataloader_idx=add_dataloader_idx,\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 400, in log\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     value, object, self.__check_allowed, name, value, wrong_dtype=(numbers.Number, Metric, Tensor, dict)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/apply_func.py\", line 96, in apply_to_collection\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     return function(data, *args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 533, in __check_allowed\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m     raise ValueError(f\"`self.log({name}, {value})` was called, but `{type(v).__name__}` values cannot be logged\")\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m ValueError: `self.log(ptl/train_AUROC, None)` was called, but `NoneType` values cannot be logged\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m \n",
            "2021-08-27 02:04:48,677\tERROR trial_runner.py:773 -- Trial train_mnist_tune_25513_00000: Error processing event.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py\", line 739, in _process_trial\n",
            "    results = self.trial_executor.fetch_result(trial)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py\", line 746, in fetch_result\n",
            "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\", line 82, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/worker.py\", line 1621, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=667, ip=172.28.0.2, repr=<ray.tune.function_runner.ImplicitFunc object at 0x7f9cf0466c90>)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 178, in train_buffered\n",
            "    result = self.train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 237, in train\n",
            "    result = self.step()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 379, in step\n",
            "    self._report_thread_runner_error(block=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 527, in _report_thread_runner_error\n",
            "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
            "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
            "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=667, ip=172.28.0.2, repr=<ray.tune.function_runner.ImplicitFunc object at 0x7f9cf0466c90>)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 260, in run\n",
            "    self._entrypoint()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 329, in entrypoint\n",
            "    self._status_reporter.get_checkpoint())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 594, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 353, in _inner\n",
            "    inner(config, checkpoint_dir=None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 344, in inner\n",
            "    trainable(config, **fn_kwargs)\n",
            "  File \"/content/ray/python/ray/tune/examples/mnist_pytorch_lightning.py\", line 222, in train_mnist_tune\n",
            "    trainer.fit(model)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 553, in fit\n",
            "    self._run(model)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 918, in _run\n",
            "    self._dispatch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 986, in _dispatch\n",
            "    self.accelerator.start_training(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
            "    self.training_type_plugin.start_training(trainer)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in start_training\n",
            "    self._results = trainer.run_stage()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 996, in run_stage\n",
            "    return self._run_train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1045, in _run_train\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
            "    epoch_output = self.epoch_loop.run(train_dataloader)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 130, in advance\n",
            "    batch_output = self.batch_loop.run(batch, self.iteration_count, self._dataloader_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 101, in run\n",
            "    super().run(batch, batch_idx, dataloader_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 148, in advance\n",
            "    result = self._run_optimization(batch_idx, split_batch, opt_idx, optimizer)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 202, in _run_optimization\n",
            "    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 404, in _optimizer_step\n",
            "    using_lbfgs=is_lbfgs,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 1618, in optimizer_step\n",
            "    optimizer.step(closure=optimizer_closure)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 209, in step\n",
            "    self.__optimizer_step(*args, closure=closure, profiler_name=profiler_name, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/optimizer.py\", line 129, in __optimizer_step\n",
            "    trainer.accelerator.optimizer_step(optimizer, self._optimizer_idx, lambda_closure=closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 296, in optimizer_step\n",
            "    self.run_optimizer_step(optimizer, opt_idx, lambda_closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 303, in run_optimizer_step\n",
            "    self.training_type_plugin.optimizer_step(optimizer, lambda_closure=lambda_closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 226, in optimizer_step\n",
            "    optimizer.step(closure=lambda_closure, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\", line 66, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 236, in _training_step_and_backward_closure\n",
            "    result = self.training_step_and_backward(split_batch, batch_idx, opt_idx, optimizer, hiddens)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 537, in training_step_and_backward\n",
            "    result = self._training_step(split_batch, batch_idx, opt_idx, hiddens)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 307, in _training_step\n",
            "    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\", line 193, in training_step\n",
            "    return self.training_type_plugin.training_step(*step_kwargs.values())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 172, in training_step\n",
            "    return self.model.training_step(*args, **kwargs)\n",
            "  File \"/content/ray/python/ray/tune/examples/mnist_pytorch_lightning.py\", line 124, in training_step\n",
            "    self.log_dict({k: v for k, v in Dict.items() if v is not None})\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 521, in log_dict\n",
            "    add_dataloader_idx=add_dataloader_idx,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 400, in log\n",
            "    value, object, self.__check_allowed, name, value, wrong_dtype=(numbers.Number, Metric, Tensor, dict)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/apply_func.py\", line 96, in apply_to_collection\n",
            "    return function(data, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/lightning.py\", line 533, in __check_allowed\n",
            "    raise ValueError(f\"`self.log({name}, {value})` was called, but `{type(v).__name__}` values cannot be logged\")\n",
            "ValueError: `self.log(ptl/train_AUROC, None)` was called, but `NoneType` values cannot be logged\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m val 0 [0, 0, 0, 0]\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m No positive samples in targets, true positive value should be meaningless\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m 0 [tensor([6, 4, 9, 2, 5, 2, 7, 6])] [7, 7, 1, 65]\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m No positive samples in targets, true positive value should be meaningless\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m 1 [tensor([6, 4, 9, 2, 5, 2, 7, 6]), tensor([5, 0, 6, 6, 7, 1, 8, 8])] [13, 13, 3, 131]\n",
            "\u001b[2m\u001b[36m(pid=667)\u001b[0m train 0 [0, 0, 0, 0]\n",
            "Result for train_mnist_tune_25513_00000:\n",
            "  {}\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 1.4/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 2.000: None | Iter 1.000: None<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/tune_mnist_asha<br>Number of trials: 1/1 (1 ERROR)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  layer_1_size</th><th style=\"text-align: right;\">  layer_2_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_tune_25513_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">0.000354834</td><td style=\"text-align: right;\">           8</td></tr>\n",
              "</tbody>\n",
              "</table><br>Number of errored trials: 1<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_tune_25513_00000</td><td style=\"text-align: right;\">           1</td><td>/root/ray_results/tune_mnist_asha/train_mnist_tune_25513_00000_0_batch_size=8,layer_1_size=128,layer_2_size=64,lr=0.00035483_2021-08-27_02-04-43/error.txt</td></tr>\n",
              "</tbody>\n",
              "</table><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 1.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 2.000: None | Iter 1.000: None<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/tune_mnist_asha<br>Number of trials: 1/1 (1 ERROR)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  layer_1_size</th><th style=\"text-align: right;\">  layer_2_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_tune_25513_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">           128</td><td style=\"text-align: right;\">            64</td><td style=\"text-align: right;\">0.000354834</td><td style=\"text-align: right;\">           8</td></tr>\n",
              "</tbody>\n",
              "</table><br>Number of errored trials: 1<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                  </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_mnist_tune_25513_00000</td><td style=\"text-align: right;\">           1</td><td>/root/ray_results/tune_mnist_asha/train_mnist_tune_25513_00000_0_batch_size=8,layer_1_size=128,layer_2_size=64,lr=0.00035483_2021-08-27_02-04-43/error.txt</td></tr>\n",
              "</tbody>\n",
              "</table><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TuneError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/content/ray/python/ray/tune/examples/mnist_pytorch_lightning.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoke_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mtune_mnist_asha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0mtune_mnist_pbt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ray/python/ray/tune/examples/mnist_pytorch_lightning.py\u001b[0m in \u001b[0;36mtune_mnist_asha\u001b[0;34m(num_samples, num_epochs, gpus_per_trial)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mfail_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         name=\"tune_mnist_asha\")\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best hyperparameters found were: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [train_mnist_tune_25513_00000])"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4VFhHLkgwdB"
      },
      "source": [
        "%rm -rf ~/ray_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnnlpkFKVPTO"
      },
      "source": [
        "m = LightningMNISTClassifier(config = {\n",
        "        \"layer_1_size\": 32,\n",
        "        \"layer_2_size\": 64,\n",
        "        \"lr\": 1e-3,\n",
        "        \"batch_size\": 64,\n",
        "    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRPqnjttXdkN"
      },
      "source": [
        "# PGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jepmPKYCXqI0",
        "outputId": "596e4643-1763-417a-d25d-1bc01b075e06"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Progressive-GAN-pytorch'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyRHgzr0Xyss"
      },
      "source": [
        "%rm -rf ../drive/MyDrive/Logs/F/PGAN/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Fqs-cGfgtZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43bd3ee1-186b-4992-8514-dda23f2e1476"
      },
      "source": [
        "!gdown --id 17l6H61tLAu26zGuei38r_T5ssjbYUeaJ\n",
        "!tar zxf ./model_f.tgz\n",
        "!rm ./model_f.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17l6H61tLAu26zGuei38r_T5ssjbYUeaJ\n",
            "To: /content/model_f.tgz\n",
            "2.34GB [00:27, 86.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HRW98zifdRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b09611e8-c971-4506-9cce-6b23a72f702c"
      },
      "source": [
        "!git clone https://souravraha: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@github.com/souravraha/Progressive-GAN-pytorch.git\n",
        "%cd Progressive-GAN-pytorch/\n",
        "!git remote add upstream https://github.com/odegeasslbc/Progressive-GAN-pytorch.git\n",
        "!git remote -v\n",
        "!git pull upstream master\n",
        "!git checkout lightning\n",
        "!git branch\n",
        "!git config --global user.email \"souravraha@ufl.edu\"\n",
        "!git config --global user.name \"souravraha\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Progressive-GAN-pytorch'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 52 (delta 10), reused 7 (delta 1), pack-reused 22\u001b[K\n",
            "Unpacking objects: 100% (52/52), done.\n",
            "/content/Progressive-GAN-pytorch\n",
            "origin\thttps://souravraha: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@github.com/souravraha/Progressive-GAN-pytorch.git (fetch)\n",
            "origin\thttps://souravraha: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@github.com/souravraha/Progressive-GAN-pytorch.git (push)\n",
            "upstream\thttps://github.com/odegeasslbc/Progressive-GAN-pytorch.git (fetch)\n",
            "upstream\thttps://github.com/odegeasslbc/Progressive-GAN-pytorch.git (push)\n",
            "From https://github.com/odegeasslbc/Progressive-GAN-pytorch\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> upstream/master\n",
            "Already up to date.\n",
            "Branch 'lightning' set up to track remote branch 'lightning' from 'origin'.\n",
            "Switched to a new branch 'lightning'\n",
            "* \u001b[32mlightning\u001b[m\n",
            "  master\u001b[m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apmJuKLo69dM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df7bb093-8fa3-420f-fa54-d5da618c2f68"
      },
      "source": [
        "!git add -A\n",
        "!git commit -m 'resumed from checkpoint'\n",
        "!git push origin lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[lightning c96c7fa] resumed from checkpoint\n",
            " 1 file changed, 13 insertions(+), 11 deletions(-)\n",
            "Counting objects: 3, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (3/3), done.\n",
            "Writing objects: 100% (3/3), 566 bytes | 566.00 KiB/s, done.\n",
            "Total 3 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/souravraha/Progressive-GAN-pytorch.git\n",
            "   445c46b..c96c7fa  lightning -> lightning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz0zUROGCS6B"
      },
      "source": [
        "%pip install lightning-bolts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkO4DgBPhe73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "45bb55f5bf6d47ec8bf5b94d7b3d3d55",
            "ad0b866844534feeac3c2084216036a3",
            "3a36f336accb4875815f9ff8736da348",
            "bf2141a4c38b47238a916a1d7a360c8a",
            "eb2dd9b130894f7c83af4da259f41af2",
            "c69ab3c07ce34c029db2a55fe8d0bb6b",
            "acad5a95d4724ddc9793db7949cd1181",
            "0efd75ae684245798c412c1f22585f77",
            "35cd9de15a134c41ab4e56de3d93d8aa",
            "e68d5700b7fd4ab6a4ff550912612b4f",
            "ba696c25fb814586babbfbabdc4fd53d"
          ]
        },
        "outputId": "99649148-9038-4839-c608-52ec204b9e23"
      },
      "source": [
        "%run -i train.py --path ../images/train/ --out_path ../drive/MyDrive/Logs/F/PGAN/ --trial_name pganResume_01 --init_step 1 --lr 1e-4 --z_dim 100 --tanh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=4, channel=128, gpu_id=0, init_step=1, lr=0.0001, n_critic=1, out_path='../drive/MyDrive/Logs/F/PGAN/', path='../images/train/', pixel_norm=False, tanh=True, total_iter=300000, trial_name='pganResume_01', z_dim=100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45bb55f5bf6d47ec8bf5b94d7b3d3d55",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/300000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3658: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "500; G: -2.561; D: 0.097; Grad: 0.216; Alpha: 0.020\n",
            "1000; G: -1.378; D: -0.019; Grad: 0.084; Alpha: 0.040\n",
            "1500; G: -0.923; D: 0.031; Grad: 0.109; Alpha: 0.060\n",
            "2000; G: -0.424; D: 0.075; Grad: 0.148; Alpha: 0.080\n",
            "2500; G: -0.011; D: 0.104; Grad: 0.125; Alpha: 0.100\n",
            "3000; G: -0.095; D: 0.130; Grad: 0.117; Alpha: 0.120\n",
            "3500; G: -0.209; D: 0.147; Grad: 0.107; Alpha: 0.140\n",
            "4000; G: -0.459; D: 0.124; Grad: 0.109; Alpha: 0.160\n",
            "4500; G: -0.006; D: 0.136; Grad: 0.107; Alpha: 0.180\n",
            "5000; G: 0.066; D: 0.116; Grad: 0.102; Alpha: 0.200\n",
            "5500; G: 0.177; D: 0.126; Grad: 0.104; Alpha: 0.220\n",
            "6000; G: -0.092; D: 0.129; Grad: 0.103; Alpha: 0.240\n",
            "6500; G: -0.197; D: 0.146; Grad: 0.104; Alpha: 0.260\n",
            "7000; G: -0.163; D: 0.158; Grad: 0.101; Alpha: 0.280\n",
            "7500; G: -0.147; D: 0.160; Grad: 0.100; Alpha: 0.300\n",
            "8000; G: -0.070; D: 0.159; Grad: 0.094; Alpha: 0.320\n",
            "8500; G: 0.123; D: 0.164; Grad: 0.106; Alpha: 0.340\n",
            "9000; G: 0.203; D: 0.153; Grad: 0.103; Alpha: 0.360\n",
            "9500; G: 0.251; D: 0.175; Grad: 0.102; Alpha: 0.380\n",
            "10000; G: 0.197; D: 0.167; Grad: 0.107; Alpha: 0.400\n",
            "10500; G: 0.163; D: 0.168; Grad: 0.103; Alpha: 0.420\n",
            "11000; G: 0.230; D: 0.173; Grad: 0.104; Alpha: 0.440\n",
            "11500; G: 0.122; D: 0.168; Grad: 0.109; Alpha: 0.460\n",
            "12000; G: -0.037; D: 0.170; Grad: 0.115; Alpha: 0.480\n",
            "12500; G: -0.085; D: 0.161; Grad: 0.103; Alpha: 0.500\n",
            "13000; G: 0.062; D: 0.167; Grad: 0.103; Alpha: 0.520\n",
            "13500; G: -0.102; D: 0.163; Grad: 0.102; Alpha: 0.540\n",
            "14000; G: -0.117; D: 0.166; Grad: 0.107; Alpha: 0.560\n",
            "14500; G: -0.007; D: 0.160; Grad: 0.101; Alpha: 0.580\n",
            "15000; G: -0.087; D: 0.161; Grad: 0.103; Alpha: 0.600\n",
            "15500; G: 0.016; D: 0.158; Grad: 0.100; Alpha: 0.620\n",
            "16000; G: 0.001; D: 0.153; Grad: 0.102; Alpha: 0.640\n",
            "16500; G: 0.091; D: 0.154; Grad: 0.097; Alpha: 0.660\n",
            "17000; G: -0.001; D: 0.155; Grad: 0.103; Alpha: 0.680\n",
            "17500; G: -0.033; D: 0.152; Grad: 0.104; Alpha: 0.700\n",
            "18000; G: 0.002; D: 0.156; Grad: 0.096; Alpha: 0.720\n",
            "18500; G: 0.035; D: 0.152; Grad: 0.094; Alpha: 0.740\n",
            "19000; G: 0.001; D: 0.146; Grad: 0.098; Alpha: 0.760\n",
            "19500; G: 0.117; D: 0.149; Grad: 0.097; Alpha: 0.780\n",
            "20000; G: 0.077; D: 0.152; Grad: 0.095; Alpha: 0.800\n",
            "20500; G: 0.147; D: 0.144; Grad: 0.099; Alpha: 0.820\n",
            "21000; G: 0.208; D: 0.145; Grad: 0.104; Alpha: 0.840\n",
            "21500; G: 0.199; D: 0.146; Grad: 0.095; Alpha: 0.860\n",
            "22000; G: 0.151; D: 0.136; Grad: 0.088; Alpha: 0.880\n",
            "22500; G: 0.156; D: 0.137; Grad: 0.102; Alpha: 0.900\n",
            "23000; G: 0.137; D: 0.137; Grad: 0.093; Alpha: 0.920\n",
            "23500; G: 0.120; D: 0.133; Grad: 0.096; Alpha: 0.940\n",
            "24000; G: 0.117; D: 0.132; Grad: 0.092; Alpha: 0.960\n",
            "24500; G: 0.217; D: 0.136; Grad: 0.098; Alpha: 0.980\n",
            "25000; G: 0.150; D: 0.136; Grad: 0.092; Alpha: 1.000\n",
            "25500; G: 0.197; D: 0.136; Grad: 0.089; Alpha: 1.000\n",
            "26000; G: 0.115; D: 0.138; Grad: 0.092; Alpha: 1.000\n",
            "26500; G: 0.106; D: 0.135; Grad: 0.096; Alpha: 1.000\n",
            "27000; G: 0.089; D: 0.136; Grad: 0.098; Alpha: 1.000\n",
            "27500; G: 0.119; D: 0.135; Grad: 0.098; Alpha: 1.000\n",
            "28000; G: 0.135; D: 0.134; Grad: 0.093; Alpha: 1.000\n",
            "28500; G: 0.075; D: 0.135; Grad: 0.100; Alpha: 1.000\n",
            "29000; G: 0.076; D: 0.144; Grad: 0.089; Alpha: 1.000\n",
            "29500; G: 0.052; D: 0.134; Grad: 0.100; Alpha: 1.000\n",
            "30000; G: 0.160; D: 0.135; Grad: 0.095; Alpha: 1.000\n",
            "30500; G: 0.106; D: 0.136; Grad: 0.099; Alpha: 1.000\n",
            "31000; G: 0.153; D: 0.138; Grad: 0.095; Alpha: 1.000\n",
            "31500; G: 0.075; D: 0.135; Grad: 0.091; Alpha: 1.000\n",
            "32000; G: 0.057; D: 0.138; Grad: 0.097; Alpha: 1.000\n",
            "32500; G: 0.098; D: 0.140; Grad: 0.095; Alpha: 1.000\n",
            "33000; G: 0.084; D: 0.133; Grad: 0.094; Alpha: 1.000\n",
            "33500; G: 0.129; D: 0.132; Grad: 0.094; Alpha: 1.000\n",
            "34000; G: 0.145; D: 0.133; Grad: 0.087; Alpha: 1.000\n",
            "34500; G: 0.132; D: 0.140; Grad: 0.094; Alpha: 1.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/300000 [1:14:58<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:10:35<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:09:03<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:06:58<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:06:43<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:14:58<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:03:52<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:10:35<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:09:03<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:06:58<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:06:43<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:03:53<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "35000; G: 0.063; D: 0.137; Grad: 0.092; Alpha: 1.000\n",
            "35500; G: 0.087; D: 0.134; Grad: 0.096; Alpha: 1.000\n",
            "36000; G: 0.055; D: 0.131; Grad: 0.091; Alpha: 1.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/300000 [1:15:57<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:11:34<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:10:02<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:07:58<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:07:42<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:04:52<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:15:58<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:11:35<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:10:02<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:07:58<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:07:43<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:04:52<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "36500; G: 0.085; D: 0.132; Grad: 0.088; Alpha: 1.000\n",
            "37000; G: 0.085; D: 0.128; Grad: 0.094; Alpha: 1.000\n",
            "37500; G: 0.067; D: 0.125; Grad: 0.090; Alpha: 1.000\n",
            "38000; G: 0.069; D: 0.131; Grad: 0.086; Alpha: 1.000\n",
            "38500; G: 0.082; D: 0.124; Grad: 0.087; Alpha: 1.000\n",
            "39000; G: 0.052; D: 0.130; Grad: 0.088; Alpha: 1.000\n",
            "39500; G: 0.135; D: 0.131; Grad: 0.089; Alpha: 1.000\n",
            "40000; G: 0.061; D: 0.126; Grad: 0.091; Alpha: 1.000\n",
            "40500; G: 0.127; D: 0.128; Grad: 0.090; Alpha: 1.000\n",
            "41000; G: -0.018; D: 0.126; Grad: 0.089; Alpha: 1.000\n",
            "41500; G: 0.088; D: 0.124; Grad: 0.087; Alpha: 1.000\n",
            "42000; G: 0.148; D: 0.120; Grad: 0.091; Alpha: 1.000\n",
            "42500; G: 0.124; D: 0.123; Grad: 0.087; Alpha: 1.000\n",
            "43000; G: 0.143; D: 0.126; Grad: 0.087; Alpha: 1.000\n",
            "43500; G: 0.070; D: 0.117; Grad: 0.090; Alpha: 1.000\n",
            "44000; G: 0.071; D: 0.117; Grad: 0.093; Alpha: 1.000\n",
            "44500; G: 0.063; D: 0.114; Grad: 0.088; Alpha: 1.000\n",
            "45000; G: 0.025; D: 0.116; Grad: 0.087; Alpha: 1.000\n",
            "45500; G: 0.089; D: 0.119; Grad: 0.086; Alpha: 1.000\n",
            "46000; G: 0.018; D: 0.118; Grad: 0.083; Alpha: 1.000\n",
            "46500; G: 0.105; D: 0.120; Grad: 0.087; Alpha: 1.000\n",
            "47000; G: 0.091; D: 0.114; Grad: 0.090; Alpha: 1.000\n",
            "47500; G: 0.147; D: 0.112; Grad: 0.091; Alpha: 1.000\n",
            "48000; G: 0.139; D: 0.119; Grad: 0.091; Alpha: 1.000\n",
            "48500; G: 0.012; D: 0.111; Grad: 0.095; Alpha: 1.000\n",
            "49000; G: 0.098; D: 0.119; Grad: 0.088; Alpha: 1.000\n",
            "49500; G: 0.159; D: 0.117; Grad: 0.086; Alpha: 1.000\n",
            "50000; G: 0.178; D: 0.108; Grad: 0.087; Alpha: 1.000\n",
            "50500; G: 0.427; D: 0.210; Grad: 0.149; Alpha: 0.020\n",
            "51000; G: -0.008; D: 0.287; Grad: 0.101; Alpha: 0.040\n",
            "51500; G: -0.172; D: 0.579; Grad: 0.089; Alpha: 0.060\n",
            "52000; G: -0.276; D: 0.708; Grad: 0.084; Alpha: 0.080\n",
            "52500; G: -0.070; D: 0.628; Grad: 0.048; Alpha: 0.100\n",
            "53000; G: 0.234; D: 0.665; Grad: 0.044; Alpha: 0.120\n",
            "53500; G: 0.241; D: 0.666; Grad: 0.079; Alpha: 0.140\n",
            "54000; G: 0.626; D: 0.665; Grad: 0.071; Alpha: 0.160\n",
            "54500; G: 0.520; D: 0.428; Grad: 0.062; Alpha: 0.180\n",
            "55000; G: 0.511; D: 0.354; Grad: 0.062; Alpha: 0.200\n",
            "55500; G: 0.518; D: 0.582; Grad: 0.070; Alpha: 0.220\n",
            "56000; G: 0.166; D: 0.520; Grad: 0.070; Alpha: 0.240\n",
            "56500; G: 0.182; D: 0.483; Grad: 0.061; Alpha: 0.260\n",
            "57000; G: 0.507; D: 0.496; Grad: 0.060; Alpha: 0.280\n",
            "57500; G: 0.376; D: 0.586; Grad: 0.071; Alpha: 0.300\n",
            "58000; G: 0.414; D: 0.596; Grad: 0.069; Alpha: 0.320\n",
            "58500; G: 0.342; D: 0.584; Grad: 0.081; Alpha: 0.340\n",
            "59000; G: 0.445; D: 0.582; Grad: 0.087; Alpha: 0.360\n",
            "59500; G: 0.420; D: 0.586; Grad: 0.087; Alpha: 0.380\n",
            "60000; G: 0.561; D: 0.553; Grad: 0.077; Alpha: 0.400\n",
            "60500; G: 0.193; D: 0.530; Grad: 0.085; Alpha: 0.420\n",
            "61000; G: 0.018; D: 0.496; Grad: 0.082; Alpha: 0.440\n",
            "61500; G: 0.127; D: 0.497; Grad: 0.082; Alpha: 0.460\n",
            "62000; G: 0.023; D: 0.492; Grad: 0.083; Alpha: 0.480\n",
            "62500; G: 0.134; D: 0.498; Grad: 0.080; Alpha: 0.500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/300000 [1:40:14<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:35:50<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:34:18<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:32:14<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:31:58<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:29:08<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:40:14<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:35:51<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:34:19<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:32:14<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:31:59<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:29:08<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "63000; G: 0.150; D: 0.477; Grad: 0.081; Alpha: 0.520\n",
            "63500; G: 0.249; D: 0.472; Grad: 0.082; Alpha: 0.540\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/300000 [1:41:31<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:37:08<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:35:36<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:33:32<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:33:16<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:30:26<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:41:32<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:37:09<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:35:37<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:33:32<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:33:17<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:30:26<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "64000; G: 0.245; D: 0.491; Grad: 0.085; Alpha: 0.560\n",
            "64500; G: 0.313; D: 0.494; Grad: 0.094; Alpha: 0.580\n",
            "65000; G: 0.347; D: 0.478; Grad: 0.092; Alpha: 0.600\n",
            "65500; G: 0.317; D: 0.481; Grad: 0.091; Alpha: 0.620\n",
            "66000; G: 0.255; D: 0.476; Grad: 0.096; Alpha: 0.640\n",
            "66500; G: 0.398; D: 0.473; Grad: 0.096; Alpha: 0.660\n",
            "67000; G: 0.405; D: 0.476; Grad: 0.102; Alpha: 0.680\n",
            "67500; G: 0.216; D: 0.476; Grad: 0.097; Alpha: 0.700\n",
            "68000; G: 0.252; D: 0.454; Grad: 0.095; Alpha: 0.720\n",
            "68500; G: 0.309; D: 0.448; Grad: 0.090; Alpha: 0.740\n",
            "69000; G: 0.313; D: 0.441; Grad: 0.084; Alpha: 0.760\n",
            "69500; G: 0.371; D: 0.464; Grad: 0.096; Alpha: 0.780\n",
            "70000; G: 0.330; D: 0.438; Grad: 0.088; Alpha: 0.800\n",
            "70500; G: 0.338; D: 0.428; Grad: 0.089; Alpha: 0.820\n",
            "71000; G: 0.340; D: 0.433; Grad: 0.090; Alpha: 0.840\n",
            "71500; G: 0.409; D: 0.426; Grad: 0.088; Alpha: 0.860\n",
            "72000; G: 0.442; D: 0.398; Grad: 0.085; Alpha: 0.880\n",
            "72500; G: 0.501; D: 0.399; Grad: 0.083; Alpha: 0.900\n",
            "73000; G: 0.429; D: 0.391; Grad: 0.088; Alpha: 0.920\n",
            "73500; G: 0.456; D: 0.382; Grad: 0.083; Alpha: 0.940\n",
            "74000; G: 0.486; D: 0.369; Grad: 0.080; Alpha: 0.960\n",
            "74500; G: 0.518; D: 0.362; Grad: 0.085; Alpha: 0.980\n",
            "75000; G: 0.566; D: 0.340; Grad: 0.080; Alpha: 1.000\n",
            "75500; G: 0.410; D: 0.340; Grad: 0.082; Alpha: 1.000\n",
            "76000; G: 0.224; D: 0.353; Grad: 0.085; Alpha: 1.000\n",
            "76500; G: 0.271; D: 0.349; Grad: 0.080; Alpha: 1.000\n",
            "77000; G: 0.312; D: 0.345; Grad: 0.084; Alpha: 1.000\n",
            "77500; G: 0.294; D: 0.338; Grad: 0.080; Alpha: 1.000\n",
            "78000; G: 0.223; D: 0.334; Grad: 0.080; Alpha: 1.000\n",
            "78500; G: 0.237; D: 0.324; Grad: 0.082; Alpha: 1.000\n",
            "79000; G: 0.225; D: 0.330; Grad: 0.082; Alpha: 1.000\n",
            "79500; G: 0.186; D: 0.315; Grad: 0.081; Alpha: 1.000\n",
            "80000; G: 0.198; D: 0.324; Grad: 0.083; Alpha: 1.000\n",
            "80500; G: 0.102; D: 0.321; Grad: 0.084; Alpha: 1.000\n",
            "81000; G: 0.062; D: 0.324; Grad: 0.082; Alpha: 1.000\n",
            "81500; G: 0.027; D: 0.298; Grad: 0.081; Alpha: 1.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/300000 [2:00:36<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:56:13<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:54:41<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:52:37<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:52:21<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:49:31<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:00:36<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:56:13<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:54:41<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:52:37<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:52:21<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:49:31<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:00:36<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:56:13<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:54:41<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:52:37<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:52:21<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:49:31<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "82000; G: 0.009; D: 0.301; Grad: 0.085; Alpha: 1.000\n",
            "82500; G: 0.088; D: 0.303; Grad: 0.081; Alpha: 1.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/300000 [2:01:55<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:57:32<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:56:00<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:53:56<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:53:40<?, ?it/s]\n",
            "  0%|          | 0/300000 [1:50:50<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "83000; G: 0.253; D: 0.300; Grad: 0.082; Alpha: 1.000\n",
            "83500; G: 0.157; D: 0.290; Grad: 0.084; Alpha: 1.000\n",
            "84000; G: 0.120; D: 0.287; Grad: 0.080; Alpha: 1.000\n",
            "84500; G: 0.051; D: 0.288; Grad: 0.082; Alpha: 1.000\n",
            "85000; G: 0.101; D: 0.268; Grad: 0.076; Alpha: 1.000\n",
            "85500; G: 0.278; D: 0.283; Grad: 0.077; Alpha: 1.000\n",
            "86000; G: 0.168; D: 0.279; Grad: 0.083; Alpha: 1.000\n",
            "86500; G: 0.111; D: 0.265; Grad: 0.078; Alpha: 1.000\n",
            "87000; G: 0.234; D: 0.268; Grad: 0.076; Alpha: 1.000\n",
            "87500; G: 0.206; D: 0.256; Grad: 0.077; Alpha: 1.000\n",
            "88000; G: 0.254; D: 0.254; Grad: 0.075; Alpha: 1.000\n",
            "88500; G: 0.165; D: 0.253; Grad: 0.078; Alpha: 1.000\n",
            "89000; G: 0.205; D: 0.240; Grad: 0.071; Alpha: 1.000\n",
            "89500; G: 0.266; D: 0.256; Grad: 0.078; Alpha: 1.000\n",
            "90000; G: 0.265; D: 0.243; Grad: 0.079; Alpha: 1.000\n",
            "90500; G: 0.314; D: 0.235; Grad: 0.077; Alpha: 1.000\n",
            "91000; G: 0.209; D: 0.232; Grad: 0.075; Alpha: 1.000\n",
            "91500; G: 0.217; D: 0.223; Grad: 0.076; Alpha: 1.000\n",
            "92000; G: 0.214; D: 0.223; Grad: 0.071; Alpha: 1.000\n",
            "92500; G: 0.187; D: 0.224; Grad: 0.072; Alpha: 1.000\n",
            "93000; G: 0.230; D: 0.215; Grad: 0.070; Alpha: 1.000\n",
            "93500; G: 0.228; D: 0.214; Grad: 0.072; Alpha: 1.000\n",
            "94000; G: 0.013; D: 0.196; Grad: 0.069; Alpha: 1.000\n",
            "94500; G: 0.249; D: 0.197; Grad: 0.074; Alpha: 1.000\n",
            "95000; G: 0.283; D: 0.213; Grad: 0.072; Alpha: 1.000\n",
            "95500; G: 0.268; D: 0.209; Grad: 0.067; Alpha: 1.000\n",
            "96000; G: 0.218; D: 0.205; Grad: 0.069; Alpha: 1.000\n",
            "96500; G: 0.192; D: 0.189; Grad: 0.073; Alpha: 1.000\n",
            "97000; G: 0.168; D: 0.192; Grad: 0.070; Alpha: 1.000\n",
            "97500; G: 0.243; D: 0.179; Grad: 0.070; Alpha: 1.000\n",
            "98000; G: 0.129; D: 0.185; Grad: 0.073; Alpha: 1.000\n",
            "98500; G: 0.192; D: 0.175; Grad: 0.068; Alpha: 1.000\n",
            "99000; G: 0.257; D: 0.178; Grad: 0.067; Alpha: 1.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/300000 [2:18:41<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:14:18<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:12:46<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:10:41<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:10:26<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:07:35<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "99500; G: 0.170; D: 0.173; Grad: 0.069; Alpha: 1.000\n",
            "100000; G: 0.208; D: 0.165; Grad: 0.071; Alpha: 1.000\n",
            "100500; G: 1.102; D: 0.221; Grad: 0.126; Alpha: 0.020\n",
            "101000; G: 0.721; D: 0.280; Grad: 0.076; Alpha: 0.040\n",
            "101500; G: 0.690; D: 0.339; Grad: 0.078; Alpha: 0.060\n",
            "102000; G: 0.807; D: 0.416; Grad: 0.081; Alpha: 0.080\n",
            "102500; G: 1.241; D: 0.529; Grad: 0.085; Alpha: 0.100\n",
            "103000; G: 1.296; D: 0.582; Grad: 0.079; Alpha: 0.120\n",
            "103500; G: 1.401; D: 0.567; Grad: 0.078; Alpha: 0.140\n",
            "104000; G: 1.255; D: 0.528; Grad: 0.074; Alpha: 0.160\n",
            "104500; G: 1.144; D: 0.426; Grad: 0.056; Alpha: 0.180\n",
            "105000; G: 0.694; D: 0.373; Grad: 0.053; Alpha: 0.200\n",
            "105500; G: 0.748; D: 0.334; Grad: 0.058; Alpha: 0.220\n",
            "106000; G: 0.505; D: 0.376; Grad: 0.062; Alpha: 0.240\n",
            "106500; G: 0.495; D: 0.406; Grad: 0.061; Alpha: 0.260\n",
            "107000; G: 0.597; D: 0.420; Grad: 0.067; Alpha: 0.280\n",
            "107500; G: 0.758; D: 0.392; Grad: 0.065; Alpha: 0.300\n",
            "108000; G: 0.640; D: 0.366; Grad: 0.063; Alpha: 0.320\n",
            "108500; G: 0.755; D: 0.363; Grad: 0.063; Alpha: 0.340\n",
            "109000; G: 0.652; D: 0.348; Grad: 0.063; Alpha: 0.360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/300000 [2:37:57<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:33:34<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:32:02<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:29:58<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:29:42<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:26:52<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "109500; G: 0.760; D: 0.341; Grad: 0.063; Alpha: 0.380\n",
            "110000; G: 0.609; D: 0.327; Grad: 0.071; Alpha: 0.400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/300000 [2:40:28<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:36:05<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:34:33<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:32:29<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:32:13<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:29:23<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:40:28<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:36:05<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:34:33<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:32:29<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:32:13<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:29:23<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:40:29<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:36:06<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:34:34<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:32:29<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:32:14<?, ?it/s]\n",
            "  0%|          | 0/300000 [2:29:23<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "110500; G: 0.649; D: 0.332; Grad: 0.067; Alpha: 0.420\n",
            "111000; G: 0.576; D: 0.343; Grad: 0.066; Alpha: 0.440\n",
            "111500; G: 0.454; D: 0.324; Grad: 0.062; Alpha: 0.460\n",
            "112000; G: 0.462; D: 0.303; Grad: 0.064; Alpha: 0.480\n",
            "112500; G: 0.543; D: 0.312; Grad: 0.065; Alpha: 0.500\n",
            "113000; G: 0.518; D: 0.293; Grad: 0.059; Alpha: 0.520\n",
            "113500; G: 0.615; D: 0.294; Grad: 0.058; Alpha: 0.540\n",
            "114000; G: 0.402; D: 0.263; Grad: 0.057; Alpha: 0.560\n",
            "114500; G: 0.471; D: 0.275; Grad: 0.059; Alpha: 0.580\n",
            "115000; G: 0.681; D: 0.260; Grad: 0.058; Alpha: 0.600\n",
            "115500; G: 0.570; D: 0.238; Grad: 0.055; Alpha: 0.620\n",
            "116000; G: 0.541; D: 0.245; Grad: 0.051; Alpha: 0.640\n",
            "116500; G: 0.529; D: 0.245; Grad: 0.052; Alpha: 0.660\n",
            "117000; G: 0.441; D: 0.224; Grad: 0.053; Alpha: 0.680\n",
            "117500; G: 0.515; D: 0.220; Grad: 0.054; Alpha: 0.700\n",
            "118000; G: 0.444; D: 0.214; Grad: 0.051; Alpha: 0.720\n",
            "118500; G: 0.560; D: 0.198; Grad: 0.049; Alpha: 0.740\n",
            "119000; G: 0.458; D: 0.210; Grad: 0.050; Alpha: 0.760\n",
            "119500; G: 0.603; D: 0.185; Grad: 0.045; Alpha: 0.780\n",
            "120000; G: 0.350; D: 0.172; Grad: 0.046; Alpha: 0.800\n",
            "120500; G: 0.507; D: 0.171; Grad: 0.045; Alpha: 0.820\n",
            "121000; G: 0.665; D: 0.176; Grad: 0.048; Alpha: 0.840\n",
            "121500; G: 0.344; D: 0.155; Grad: 0.039; Alpha: 0.860\n",
            "122000; G: 0.354; D: 0.134; Grad: 0.039; Alpha: 0.880\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVLJP_gOCbD9"
      },
      "source": [
        "## Facebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwZzGUvYDFAo",
        "outputId": "9ff72498-671f-4ddf-93e9-00387a675eda"
      },
      "source": [
        "!git clone https://souravraha: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@github.com/souravraha/pytorch_GAN_zoo.git\n",
        "%cd pytorch_GAN_zoo/\n",
        "!git remote add upstream https://github.com/facebookresearch/pytorch_GAN_zoo.git\n",
        "!git remote -v\n",
        "!git pull upstream master\n",
        "!git checkout lightning\n",
        "!git branch\n",
        "!git config --global user.email \"souravraha@ufl.edu\"\n",
        "!git config --global user.name \"souravraha\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch_GAN_zoo'...\n",
            "remote: Enumerating objects: 1537, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 1537 (delta 22), reused 21 (delta 7), pack-reused 1495\u001b[K\n",
            "Receiving objects: 100% (1537/1537), 2.07 MiB | 27.20 MiB/s, done.\n",
            "Resolving deltas: 100% (982/982), done.\n",
            "/content/pytorch_GAN_zoo\n",
            "origin\thttps://souravraha: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@github.com/souravraha/pytorch_GAN_zoo.git (fetch)\n",
            "origin\thttps://souravraha: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@github.com/souravraha/pytorch_GAN_zoo.git (push)\n",
            "upstream\thttps://github.com/facebookresearch/pytorch_GAN_zoo.git (fetch)\n",
            "upstream\thttps://github.com/facebookresearch/pytorch_GAN_zoo.git (push)\n",
            "From https://github.com/facebookresearch/pytorch_GAN_zoo\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> upstream/master\n",
            "Already up to date.\n",
            "Branch 'lightning' set up to track remote branch 'lightning' from 'origin'.\n",
            "Switched to a new branch 'lightning'\n",
            "* \u001b[32mlightning\u001b[m\n",
            "  master\u001b[m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XYyIPxuDFAt",
        "outputId": "676cee78-ee66-4078-9034-41b35fc707f9"
      },
      "source": [
        "!git add -A\n",
        "!git commit -m 'changed normalize'\n",
        "!git push origin lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[lightning 1c3c0f2] changed normalize\n",
            " 2 files changed, 2 insertions(+), 1 deletion(-)\n",
            " create mode 100644 npyImageData.json\n",
            "Counting objects: 6, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (6/6), done.\n",
            "Writing objects: 100% (6/6), 591 bytes | 591.00 KiB/s, done.\n",
            "Total 6 (delta 4), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
            "To https://github.com/souravraha/pytorch_GAN_zoo.git\n",
            "   2838a5f..1c3c0f2  lightning -> lightning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsywObdvXoUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb5ceb7-eed6-49df-e182-2a27241c946c"
      },
      "source": [
        "%pip install -q -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 676 kB 15.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 404 kB 80.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 269 kB 81.3 MB/s \n",
            "\u001b[?25h  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atOMFQbiaVuj"
      },
      "source": [
        "from torchvision.datasets import CIFAR10, CelebA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oLKKawJahHZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161,
          "referenced_widgets": [
            "33d6f6065f3f47cabcdfbe3eb66cec0e",
            "e0470e69f5ee422ebdb8f52e103ec8c1",
            "9ba970c589ba499a8c1517dda5e5c3d3",
            "77ba069e5cf44e379931e6ab3d8dca4b",
            "73822e6403614dc8b9bd69b574255f9e",
            "cc08c71f784e4a2a9eddeb2de95c8792",
            "ad662c6fcfad4fe2bbf4df8ef79bc73a",
            "176645ddbf0844aebed638f535015063",
            "2324b127888048b7ae800836db3c3a99",
            "04e3c2e2a52b4f08a170b6dcd83a86b0",
            "e4d17e24dfb2449ca3daa53bc2f26102"
          ]
        },
        "outputId": "ec258240-df24-404a-d4d0-98e42b25610c"
      },
      "source": [
        "CIFAR10('../',download=True)\n",
        "# CelebA('../', download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33d6f6065f3f47cabcdfbe3eb66cec0e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../cifar-10-python.tar.gz to ../\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: ../\n",
              "    Split: Train"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_ZWLPiuGta0",
        "outputId": "30d2948a-3f38-453a-f029-bfafe57fd551"
      },
      "source": [
        "%run -i train.py DCGAN --overrides"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: train.py [-h] [--no_vis] [--np_vis] [--restart] [-n NAME] [-d DIR]\n",
            "                [-c CONFIGPATH] [-s SAVEITER] [-e EVALITER] [-S SCALE_ITER]\n",
            "                [-v PARTITION_VALUE] [--depth DEPTH]\n",
            "                [--miniBatchSize MINIBATCHSIZE]\n",
            "                [--dimLatentVector DIMLATENTVECTOR] [--dimOutput DIMOUTPUT]\n",
            "                [--dimG DIMG] [--dimD DIMD] [--lossMode LOSSMODE]\n",
            "                [--lambdaGP LAMBDAGP] [--sigmaNoise SIGMANOISE]\n",
            "                [--epsilonD EPSILOND] [--baseLearningRate BASELEARNINGRATE]\n",
            "                [--weightConditionG WEIGHTCONDITIONG]\n",
            "                [--weightConditionD WEIGHTCONDITIOND] [--GDPP GDPP]\n",
            "                [--nEpoch NEPOCH] [--overrides]\n",
            "                model_name\n",
            "\n",
            "Testing script\n",
            "\n",
            "positional arguments:\n",
            "  model_name            Name of the model to launch, available models are\n",
            "                        PGAN, PPGAN adn StyleGAN. To get all possible option\n",
            "                        for a model please run train.py $MODEL_NAME -overrides\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --no_vis              Disable all visualizations\n",
            "  --np_vis              Replace visdom by a numpy based visualizer (SLURM)\n",
            "  --restart             If a checkpoint is detected, do not try to load it\n",
            "  -n NAME, --name NAME  Model's name\n",
            "  -d DIR, --dir DIR     Output directory\n",
            "  -c CONFIGPATH, --config CONFIGPATH\n",
            "                        Model's name\n",
            "  -s SAVEITER, --save_iter SAVEITER\n",
            "                        If it applies, frequence at which a checkpoint should\n",
            "                        be saved. In the case of a evaluation test, iteration\n",
            "                        to work on.\n",
            "  -e EVALITER, --eval_iter EVALITER\n",
            "                        If it applies, frequence at which a checkpoint should\n",
            "                        be saved\n",
            "  -S SCALE_ITER, --Scale_iter SCALE_ITER\n",
            "                        If it applies, scale to work on\n",
            "  -v PARTITION_VALUE, --partitionValue PARTITION_VALUE\n",
            "                        Partition's value\n",
            "  --depth DEPTH\n",
            "  --miniBatchSize MINIBATCHSIZE\n",
            "  --dimLatentVector DIMLATENTVECTOR\n",
            "  --dimOutput DIMOUTPUT\n",
            "  --dimG DIMG\n",
            "  --dimD DIMD\n",
            "  --lossMode LOSSMODE\n",
            "  --lambdaGP LAMBDAGP\n",
            "  --sigmaNoise SIGMANOISE\n",
            "  --epsilonD EPSILOND\n",
            "  --baseLearningRate BASELEARNINGRATE\n",
            "  --weightConditionG WEIGHTCONDITIONG\n",
            "  --weightConditionD WEIGHTCONDITIOND\n",
            "  --GDPP GDPP\n",
            "  --nEpoch NEPOCH\n",
            "  --overrides           For more information on attribute parameters, please\n",
            "                        have a look at models/trainer/standard_configurations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsd7kFq0K7IO",
        "outputId": "1109be22-e44a-4f65-965e-b886b4dcac34"
      },
      "source": [
        "%cd ../\n",
        "!gdown --id 17l6H61tLAu26zGuei38r_T5ssjbYUeaJ\n",
        "!tar zxf ./model_f.tgz\n",
        "!rm ./model_f.tgz\n",
        "%cd pytorch_GAN_zoo/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17l6H61tLAu26zGuei38r_T5ssjbYUeaJ\n",
            "To: /content/model_f.tgz\n",
            "2.34GB [00:26, 36.2MB/s]\n",
            "/content/pytorch_GAN_zoo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaC6cG9ZLTiV"
      },
      "source": [
        "import json\n",
        "\n",
        "dict = {\n",
        "    \"pathDB\": '/content/images',\n",
        "    'config':{\n",
        "        'dimLatentVector': 100,\n",
        "        'baseLearningRate': 1e-4,\n",
        "        # 'dimOutput': 1,\n",
        "        'maxIterAtScale': [6000, 12000, 12000, 12000, 12000, 12000]\n",
        "    },\n",
        "    'imagefolderDataset': True,\n",
        "}\n",
        "with open('npyImageData.json', 'w') as f:\n",
        "    json.dump(dict, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3RyhghIfenp"
      },
      "source": [
        "json.dump()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "TAsF0NXtPYOC",
        "outputId": "c04a11bc-9907-4d44-e220-a35f3636cdc6"
      },
      "source": [
        "%run -i train.py DCGAN -c npyImageData.json -n galaxy --np_vis --restart"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running DCGAN\n",
            "size 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/content/pytorch_GAN_zoo/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m                                \u001b[0mmodelLabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelLabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                                \u001b[0mpartitionValue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitionValue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                                **trainingConfig)\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# If a checkpoint is found, load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pytorch_GAN_zoo/models/trainer/DCGAN_trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pathdb, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \"\"\"\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mGANTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlossProfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scale\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pytorch_GAN_zoo/models/trainer/gan_trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pathdb, useGPU, visualisation, lossIterEvaluation, saveIter, checkPointDir, modelLabel, config, pathAttribDict, selectedAttributes, imagefolderDataset, ignoreAttribs, pathPartition, partitionValue)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpathAttribDict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagefolderDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             self.modelConfig.attribKeysOrder = self.getDataset(\n\u001b[0;32m---> 94\u001b[0;31m                 0, size=10).getKeyOrders()\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AC-GAN classes : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pytorch_GAN_zoo/models/trainer/gan_trainer.py\u001b[0m in \u001b[0;36mgetDataset\u001b[0;34m(self, scale, size)\u001b[0m\n\u001b[1;32m    437\u001b[0m                              \u001b[0mattribDictPath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpathAttribDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                              \u001b[0mspecificAttrib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselectedAttributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                              mimicImageFolder=self.imagefolderDataset)\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minScaleUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pytorch_GAN_zoo/models/datasets/attrib_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pathdb, attribDictPath, specificAttrib, transform, mimicImageFolder, ignoreAttribs, getEqualizer, pathMask)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistImg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildStatsOnDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Empty dataset"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "6pJIkPNeXifc",
        "outputId": "49cf4412-2b90-4751-b7ee-2c0e69f566bb"
      },
      "source": [
        "%tb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/utils/py3compat.py\u001b[0m in \u001b[0;36mexecfile\u001b[0;34m(fname, glob, loc, compiler)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiler\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# Refactor print statements in doctests.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pytorch_GAN_zoo/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# done via the command line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdateParserWithConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainerModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_defaultConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     configOverride = getConfigOverrideFromParser(\n\u001b[1;32m     74\u001b[0m         kwargs, trainerModule._defaultConfig)\n",
            "\u001b[0;32m/usr/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized arguments: %s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1768\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2515\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2516\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2517\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2503\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2504\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vANjB-xEa4M5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "outputId": "249fbfc6-d047-429f-fd07-23f72252b8e6"
      },
      "source": [
        "%run -i datasets.py cifar10 ../cifar-10-batches-py -o ../images\n",
        "%run -i train.py PGAN -c config_cifar10.json --restart -n cifar10 --np_vis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unpacking CIFAR-10...\n",
            " |####################################################################################################| 100.0% \n",
            "Running PGAN\n",
            "size 10\n",
            "50000 images found\n",
            "AC-GAN classes : \n",
            "{'Main': {'order': 0, 'values': ['airplane', 'automobile', 'dog', 'horse', 'cat', 'bird', 'truck', 'deer', 'frog', 'ship']}}\n",
            "\n",
            "size 10\n",
            "50000 images found\n",
            "50000 images detected\n",
            "size (4, 4)\n",
            "50000 images found\n",
            "Changing alpha to 0.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/content/pytorch_GAN_zoo/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mGANTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadSavedTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathTmpData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mGANTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/pytorch_GAN_zoo/models/trainer/progressive_gan_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 status = self.trainOnEpoch(dbLoader, scale,\n\u001b[1;32m    236\u001b[0m                                            \u001b[0mshiftIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshiftIter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                            maxIter=self.modelConfig.maxIterAtScale[scale])\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pytorch_GAN_zoo/models/trainer/gan_trainer.py\u001b[0m in \u001b[0;36mtrainOnEpoch\u001b[0;34m(self, dbLoader, scale, shiftIter, maxIter)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# Additionnal updates inside a scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0minputs_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minScaleUpdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pytorch_GAN_zoo/models/trainer/progressive_gan_trainer.py\u001b[0m in \u001b[0;36minScaleUpdate\u001b[0;34m(self, iter, scale, input_real)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterAlphaJump\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexJumpAlpha\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphaJumpVals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexJumpAlpha\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateAlpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexJumpAlpha\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pytorch_GAN_zoo/models/progressive_gan.py\u001b[0m in \u001b[0;36mupdateAlpha\u001b[0;34m(self, newAlpha)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetNewAlpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewAlpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewAlpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1131\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GNet' object has no attribute 'module'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcMM5f1ZdxSy"
      },
      "source": [
        "python datasets.py celeba_cropped $PATH_TO_CELEBA/img_align_celeba/ -o $OUTPUT_DATASET\n",
        "python train.py PGAN -c config_celeba_cropped.json --restart -n celeba_cropped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtrtVf5Nd2dl"
      },
      "source": [
        "# ACGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygOtRS_Ie32n"
      },
      "source": [
        "!git clone https://github.com/nocotan/pytorch-lightning-gans.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2ddKYtXfG5y"
      },
      "source": [
        "%cd ./pytorch-lightning-gans/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqP0V0OAfyOc"
      },
      "source": [
        "%pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZUIrgOfbwPe"
      },
      "source": [
        "# 'a': 1Cjcw2EWorhdhJSGoWOdxsEUDxvl943dt, 'b': 15yXXC4h5VsytP3Ak1jfUSjQhdgP2s23K, 'c': 1vuQ-pLzoKT4Hd_V7949r9eND9E2fB_u_,\n",
        "# 'd': , 'e': 1wFuasvb7PthxXtMUlsD13uzYHWlWt06H, 'f': 17l6H61tLAu26zGuei38r_T5ssjbYUeaJ, \n",
        "# 'g': 1SxQVosWeEjY3Pyn8LRXA11rLnZ9HK_7B, 'h': 1Atau0RH4oyLAiYReW-G9a8l9pUNltglF, 'i': 15lEgsR1p00KSHieaT9a1nkbJ86pDxwgp, \n",
        "# 'j': 1m0EQUbqZZeyl76XsQIKWU5Qd7jGmmWhB, 'k': , 'l': 1meTDi4aeWfdChOiXeLtUOGhjVDVu000e\n",
        "\n",
        "# !rm -rf images\n",
        "!gdown --id 17l6H61tLAu26zGuei38r_T5ssjbYUeaJ\n",
        "!tar zxf ./model_f.tgz\n",
        "!rm ./model_f.tgz\n",
        "\n",
        "# def prepare_data(data_dir: str = '/content'):\n",
        "#     gdown.download('https://drive.google.com/uc?id=17l6H61tLAu26zGuei38r_T5ssjbYUeaJ', data_dir+'/model_f.tgz', quiet=True)\n",
        "    \n",
        "#     temp = tarfile.open(data_dir+'/model_f.tgz', 'r|gz')\n",
        "#     temp.extractall()\n",
        "#     temp.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw8PR7yzjMNK"
      },
      "source": [
        "%run -i ./models/acgan.py --batch_size 8 --lr 0.0001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkA9EUJ93y_8"
      },
      "source": [
        "from torchvision.utils import save_image\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqizfhhx05A5"
      },
      "source": [
        "model = ACGAN.load_from_checkpoint('./lightning_logs/version_9/checkpoints/epoch=14-step=7019.ckpt')\n",
        "sample_imgs = model(torch.randn(3, 100), torch.arange(3))\n",
        "save_image(F.interpolate(sample_imgs, 150),'Fake_15.png', normalize=True, value_range=(-1, 1))\n",
        "Image.open('./Fake_15.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLyyH5m5wkwO"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard  --logdir ./lightning_logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Az8OO8YrLOZ"
      },
      "source": [
        "torch.randint()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75mLhO3AfuRX"
      },
      "source": [
        "import os\n",
        "from argparse import ArgumentParser, Namespace\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "from pytorch_lightning.core import LightningModule\n",
        "from pytorch_lightning.trainer import Trainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiVBHSSofmcG"
      },
      "source": [
        "    def train_dataloader(self):\n",
        "        @staticmethod\n",
        "        def npy_loader(path):\n",
        "            # s=np.load(path).astype('float',copy=False)\n",
        "            return torch.from_numpy(np.load(path)).unsqueeze(0).float()\n",
        "            # Convert to tenssor first, and then to float, otherwise final dtype \n",
        "            # would be float64, which would raise errors in conv layers      ###### type as\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((32, 32)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5], [0.5]),\n",
        "        ])\n",
        "\n",
        "        dataset = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
        "        return DataLoader(dataset, batch_size=self.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}