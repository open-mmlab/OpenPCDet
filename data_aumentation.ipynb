{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit1c2d0c1c8ac7469a9224fc57cc4d9dcf",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# KITTI Dataset augmentation visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Dataset structure\n",
    "\n",
    "```\n",
    "ðŸ“¦gta\n",
    "â”— ðŸ“‚training\n",
    "  â”£ ðŸ“‚calib\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.txt\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”£ ðŸ“‚image_2\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.png\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”£ ðŸ“‚label_2\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.txt\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”— ðŸ“‚velodyne\n",
    "    â”£ ðŸ“œ<file_id>.bin\n",
    "    â”— ðŸ“œ ...\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Notebook initialized with ipy backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mayavi.mlab as mlab\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import pcdet.datasets.augmentor\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.utils import common_utils\n",
    "from tools.visual_utils import visualize_utils as V\n",
    "\n",
    "mlab.init_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate pickles from the kitti data\n",
    "# os.system(\"python -m pcdet.datasets.kitti.kitti_dataset create_kitti_infos tools/cfgs/dataset_configs/kitti_dataset.yaml\")"
   ]
  },
  {
   "source": [
    "## Visualizing the LiDAR point cloud with labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = common_utils.create_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-12 15:52:20,918   INFO  Database filter by min points Car: 14357 => 13532\n",
      "2021-04-12 15:52:20,919   INFO  Database filter by min points Pedestrian: 2207 => 2168\n",
      "2021-04-12 15:52:20,920   INFO  Database filter by min points Cyclist: 734 => 705\n",
      "2021-04-12 15:52:20,950   INFO  Database filter by difficulty Car: 13532 => 10759\n",
      "2021-04-12 15:52:20,955   INFO  Database filter by difficulty Pedestrian: 2168 => 2075\n",
      "2021-04-12 15:52:20,959   INFO  Database filter by difficulty Cyclist: 705 => 581\n",
      "2021-04-12 15:52:21,034   INFO  Loading KITTI dataset\n",
      "2021-04-12 15:52:21,149   INFO  Total samples for KITTI dataset: 3712\n",
      "2021-04-12 15:52:21,150   INFO  Total number of samples: \t3712\n",
      "2021-04-12 15:52:21,151   INFO  Loading samples\n",
      "2021-04-12 15:56:10,186   INFO  Loaded sample index: \t1\n",
      "2021-04-12 16:01:10,335   INFO  Loaded sample index: \t2\n",
      "2021-04-12 16:05:13,460   INFO  Loaded sample index: \t3\n",
      "2021-04-12 16:09:09,432   INFO  Loaded sample index: \t4\n",
      "2021-04-12 16:12:57,658   INFO  Loaded sample index: \t5\n",
      "2021-04-12 16:16:11,669   INFO  Loaded sample index: \t6\n"
     ]
    }
   ],
   "source": [
    "cfg_from_yaml_file('tools/cfgs/dataset_configs/kitti_dataset.yaml', cfg)\n",
    "# cfg_from_yaml_file('tools/cfgs/kitti_models/pointpillar_augs.yaml', cfg)\n",
    "\n",
    "cfg.DATA_PATH = 'data/kitti'\n",
    "\n",
    "train_set, train_loader, train_sampler = build_dataloader(\n",
    "    dataset_cfg=cfg,\n",
    "    class_names=['Car', 'Pedestrian', 'Cyclist'],\n",
    "    batch_size=1,\n",
    "    dist=False,\n",
    "    workers=4,\n",
    "    logger=logger,\n",
    "    training=True,\n",
    "    merge_all_iters_to_one_epoch=False,\n",
    "    total_epochs=0\n",
    ")\n",
    "\n",
    "logger.info(f'Total number of samples: \\t{len(train_set)}')\n",
    "\n",
    "data_dict_list = []\n",
    "logger.info('Loading samples')\n",
    "for idx, data_dict in enumerate(train_set):\n",
    "    logger.info(f'Loaded sample index: \\t{idx + 1}')\n",
    "    data_dict = train_set.collate_batch([data_dict])\n",
    "    data_dict_list.append(data_dict)\n",
    "    if idx > 4: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 40, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "data_dict_list[2]['gt_boxes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pc(data_dict):\n",
    "    V.draw_scenes(\n",
    "        points=data_dict['points'][:, 1:], gt_boxes=data_dict['gt_boxes'][0]\n",
    "    )\n",
    "\n",
    "    return mlab.test_plot3d()\n"
   ]
  },
  {
   "source": [
    "## Visualizing the original scene\n",
    "![Original Camera Image](data/kitti/training/image_2/000004.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9435a9ee129e4486a5acfa16f164bc29"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "show_pc(data_dict_list[2])\n",
    "mlab.savefig('figs/aug_pipeline_output.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "## Augmentation methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Random flip"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip_along_x(gt_boxes, points):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C)\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    enable = True\n",
    "    if enable:\n",
    "        gt_boxes[:, 1] = -gt_boxes[:, 1]\n",
    "        gt_boxes[:, 6] = -gt_boxes[:, 6]\n",
    "        points[:, 1] = -points[:, 1]\n",
    "\n",
    "        if gt_boxes.shape[1] > 8:\n",
    "            gt_boxes[:, 8] = -gt_boxes[:, 8]\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def random_flip_along_y(gt_boxes, points):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C)\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    enable = True\n",
    "    if enable:\n",
    "        gt_boxes[:, 0] = -gt_boxes[:, 0]\n",
    "        gt_boxes[:, 6] = -(gt_boxes[:, 6] + np.pi)\n",
    "        points[:, 0] = -points[:, 0]\n",
    "\n",
    "        if gt_boxes.shape[1] > 7:\n",
    "            gt_boxes[:, 7] = -gt_boxes[:, 7]\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b767b09244244a5ca02d49694d64fedd"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "flipped_y = deepcopy(data_dict_list[2])\n",
    "flipped_y['gt_boxes'][0], flipped_y['points'][:,1:] = random_flip_along_y(flipped_y['gt_boxes'][0], flipped_y['points'][:,1:])\n",
    "\n",
    "show_pc(flipped_y)\n",
    "mlab.savefig('figs/flipped_y.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36f27dd9f20f448988c6026aa093f3b7"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "flipped_x = deepcopy(data_dict_list[2])\n",
    "flipped_x['gt_boxes'][0], flipped_x['points'][:,1:] = random_flip_along_x(flipped_x['gt_boxes'][0], flipped_x['points'][:,1:])\n",
    "\n",
    "show_pc(flipped_x)\n",
    "mlab.savefig('figs/flipped_x.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "### Global rotation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_rotation(gt_boxes, points, rot_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        rot_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    noise_rotation = np.random.uniform(rot_range[0], rot_range[1])\n",
    "    points = common_utils.rotate_points_along_z(points[np.newaxis, :, :], np.array([noise_rotation]))[0]\n",
    "    gt_boxes[:, 0:3] = common_utils.rotate_points_along_z(gt_boxes[np.newaxis, :, 0:3], np.array([noise_rotation]))[0]\n",
    "    gt_boxes[:, 6] += noise_rotation\n",
    "    if gt_boxes.shape[1] > 8:\n",
    "        gt_boxes[:, 7:9] = common_utils.rotate_points_along_z(\n",
    "            np.hstack((gt_boxes[:, 7:9], np.zeros((gt_boxes.shape[0], 1))))[np.newaxis, :, :],\n",
    "            np.array([noise_rotation])\n",
    "        )[0][:, 0:2]\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15f38ed146064db8a98f1629bc9ee73d"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "rotated = deepcopy(data_dict_list[2])\n",
    "rotated['gt_boxes'][0], rotated['points'][:,1:] = global_rotation(rotated['gt_boxes'][0], rotated['points'][:,1:], [-0.78539816, 0.78539816])\n",
    "\n",
    "show_pc(rotated)\n",
    "mlab.savefig('figs/rotated_global.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "### Global scaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_scaling(gt_boxes, points, scale_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading]\n",
    "        points: (M, 3 + C),\n",
    "        scale_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if scale_range[1] - scale_range[0] < 1e-3:\n",
    "        return gt_boxes, points\n",
    "    noise_scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "    points[:, :3] *= noise_scale\n",
    "    gt_boxes[:, :6] *= noise_scale\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8e1e43297644a7fa3a01ad85dbfdcaa"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "scaled = deepcopy(data_dict_list[2])\n",
    "scaled['gt_boxes'][0], scaled['points'][:,1:] = global_scaling(scaled['gt_boxes'][0], scaled['points'][:, 1:], [0.2, 0.5])\n",
    "\n",
    "show_pc(scaled)\n",
    "mlab.savefig('figs/scaled_global.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "### Global translation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_translation_along_x(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "\n",
    "    points[:, 0] += offset\n",
    "    gt_boxes[:, 0] += offset\n",
    "\n",
    "    if gt_boxes.shape[1] > 7:\n",
    "        gt_boxes[:, 7] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def random_translation_along_y(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "\n",
    "    points[:, 1] += offset\n",
    "    gt_boxes[:, 1] += offset\n",
    "\n",
    "    if gt_boxes.shape[1] > 8:\n",
    "        gt_boxes[:, 8] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def random_translation_along_z(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "\n",
    "    points[:, 2] += offset\n",
    "    gt_boxes[:, 2] += offset\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "109c565297a1493a98f35a35c1abaed0"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "translation_x = deepcopy(data_dict_list[2])\n",
    "translation_x['gt_boxes'][0], translation_x['points'][:,1:] = random_translation_along_x(translation_x['gt_boxes'][0], translation_x['points'][:, 1:], [15, 20])\n",
    "\n",
    "show_pc(translation_x)\n",
    "mlab.savefig('figs/translation_global_x.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f63ef5e8ae794c4a9673bd03e76c0805"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "translation_y = deepcopy(data_dict_list[2])\n",
    "translation_y['gt_boxes'][0], translation_y['points'][:,1:] = random_translation_along_y(translation_y['gt_boxes'][0], translation_y['points'][:, 1:], [15, 20])\n",
    "\n",
    "show_pc(translation_y)\n",
    "mlab.savefig('figs/translation_global_y.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72cea0a99e8c493bae195ff1775e3d4d"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "translation_z = deepcopy(data_dict_list[2])\n",
    "translation_z['gt_boxes'][0], translation_z['points'][:,1:] = random_translation_along_z(translation_z['gt_boxes'][0], translation_z['points'][:, 1:], [15, 20])\n",
    "\n",
    "show_pc(translation_z)\n",
    "mlab.savefig('figs/translation_global_z.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "#### Aux function to find which points are inside a bounding box"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_points_in_box(points, gt_box):\n",
    "    filter_arr = []\n",
    "    for point in points:\n",
    "        x, y, z, dx, dy, dz = gt_box[0], gt_box[1], gt_box[2], gt_box[3], gt_box[4], gt_box[5]\n",
    "        if point[0] <= x + dx/2 and point[0] >= x - dx/2 \\\n",
    "            and point[1] <= y + dy/2 and point[1] >= y - dy/2 \\\n",
    "                and point[2] <= z + dz/2 and point[2] >= z - dz/2:\n",
    "                    filter_arr.append(True)\n",
    "        else:\n",
    "            filter_arr.append(False)\n",
    "\n",
    "    # points_in_box = points[filter_arr]\n",
    "    return filter_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36ae9ff168924645a3350c09b6163107"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "points_to_filter = deepcopy(data_dict_list[0])\n",
    "filter_arr = filter_points_in_box(points_to_filter['points'][:,1:], points_to_filter['gt_boxes'][0][1])\n",
    "filtered_points = points_to_filter['points'][:,1:][filter_arr]\n",
    "\n",
    "V.draw_scenes(\n",
    "        points=filtered_points, gt_boxes=points_to_filter['gt_boxes'][0,1:]\n",
    "    )\n",
    "\n",
    "mlab.savefig('figs/points_in_box.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "### Local translation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_translation_along_x(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    for idx, box in enumerate(gt_boxes):\n",
    "        offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                point[0] += offset\n",
    "\n",
    "        gt_boxes[idx, 0] += offset\n",
    "\n",
    "        if gt_boxes.shape[1] > 7:\n",
    "            gt_boxes[idx, 7] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "\n",
    "def local_translation_along_y(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    for idx, box in enumerate(gt_boxes):\n",
    "        offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                point[1] += offset\n",
    "\n",
    "        gt_boxes[idx, 1] += offset\n",
    "\n",
    "        if gt_boxes.shape[1] > 8:\n",
    "            gt_boxes[idx, 8] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "\n",
    "def local_translation_along_z(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    for idx, box in enumerate(gt_boxes):\n",
    "        offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                point[2] += offset\n",
    "\n",
    "        gt_boxes[idx, 2] += offset\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c431a90f8cb45cd985c98b6662c2e84"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "local_translation_x = deepcopy(data_dict_list[2])\n",
    "local_translation_x['gt_boxes'][0], local_translation_x['points'][:,1:] = local_translation_along_x(local_translation_x['gt_boxes'][0], local_translation_x['points'][:, 1:], [10, 15])\n",
    "\n",
    "show_pc(local_translation_x)\n",
    "mlab.savefig('figs/translation_local_x.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "604837abdd474bc9a9025e7c139eccf7"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "local_translation_y = deepcopy(data_dict_list[2])\n",
    "local_translation_y['gt_boxes'][0], local_translation_y['points'][:,1:] = local_translation_along_y(local_translation_y['gt_boxes'][0], local_translation_y['points'][:, 1:], [10, 15])\n",
    "\n",
    "show_pc(local_translation_y)\n",
    "mlab.savefig('figs/translation_local_y.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "969ad233b20c4ea5a8aec8932431f1e6"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "local_translation_z = deepcopy(data_dict_list[2])\n",
    "local_translation_z['gt_boxes'][0], local_translation_z['points'][:,1:] = local_translation_along_z(local_translation_z['gt_boxes'][0], local_translation_z['points'][:, 1:], [10, 15])\n",
    "\n",
    "show_pc(local_translation_z)\n",
    "mlab.savefig('figs/translation_local_z.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "### Local scaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_scaling(gt_boxes, points, scale_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading]\n",
    "        points: (M, 3 + C),\n",
    "        scale_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if scale_range[1] - scale_range[0] < 1e-3:\n",
    "        return gt_boxes, points\n",
    "\n",
    "    noise_scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "    for idx, box in enumerate(gt_boxes):\n",
    "        noise_scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                # tranlation to axis center\n",
    "                point[0] -= box[0]\n",
    "                point[1] -= box[1]\n",
    "                point[2] -= box[2]\n",
    "\n",
    "                # apply scaling\n",
    "                point[:3] *= noise_scale\n",
    "\n",
    "                # tranlation back to original position\n",
    "                point[0] += box[0]\n",
    "                point[1] += box[1]\n",
    "                point[2] += box[2]\n",
    "\n",
    "        gt_boxes[idx, 3:6] *= noise_scale\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa53af7f1d6f4d46b8d5380d53277783"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "scaled_local = deepcopy(data_dict_list[2])\n",
    "scaled_local['gt_boxes'][0], scaled_local['points'][:,1:] = local_scaling(scaled_local['gt_boxes'][0], scaled_local['points'][:, 1:], [0.2, 0.5])\n",
    "\n",
    "show_pc(scaled_local)\n",
    "mlab.savefig('figs/scaled_local.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "### Local rotation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_rotation(gt_boxes, points, rot_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        rot_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx, box in enumerate(gt_boxes):\n",
    "        noise_rotation = np.random.uniform(rot_range[0], rot_range[1])\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                centroid_x = box[0]\n",
    "                centroid_y = box[1]\n",
    "                centroid_z = box[2]\n",
    "\n",
    "                # tranlation to axis center\n",
    "                point[0] -= centroid_x\n",
    "                point[1] -= centroid_y\n",
    "                point[2] -= centroid_z\n",
    "                box[0] -= centroid_x\n",
    "                box[1] -= centroid_y\n",
    "                box[2] -= centroid_z\n",
    "\n",
    "                # apply rotation\n",
    "                point[:] = common_utils.rotate_points_along_z(point[np.newaxis, np.newaxis, :], np.array([noise_rotation]))[0][0]\n",
    "                box[0:3] = common_utils.rotate_points_along_z(box[np.newaxis, np.newaxis, 0:3], np.array([noise_rotation]))[0][0]\n",
    "\n",
    "                # tranlation back to original position\n",
    "                point[0] += centroid_x\n",
    "                point[1] += centroid_y\n",
    "                point[2] += centroid_z\n",
    "                box[0] += centroid_x\n",
    "                box[1] += centroid_y\n",
    "                box[2] += centroid_z\n",
    "\n",
    "        gt_boxes[idx, 6] += noise_rotation\n",
    "        if gt_boxes.shape[1] > 8:\n",
    "            gt_boxes[idx, 7:9] = common_utils.rotate_points_along_z(\n",
    "                np.hstack((gt_boxes[idx, 7:9], np.zeros((gt_boxes.shape[0], 1))))[np.newaxis, :, :],\n",
    "                np.array([noise_rotation])\n",
    "            )[0][:, 0:2]\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd4c25f29a194b29953e18a322cdd38c"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "rotated_local = deepcopy(data_dict_list[2])\n",
    "rotated_local['gt_boxes'][0], rotated_local['points'][:,1:] = local_rotation(rotated_local['gt_boxes'][0],rotated_local['points'][:, 1:], [-0.78539815, 0.78539816])\n",
    "\n",
    "show_pc(rotated_local)\n",
    "mlab.savefig('figs/rotated_local.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "Oversampling (TODO)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(gt_boxes, points, new_gt_boxes, new_points):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    #gt_boxes.reshape(len(gt_boxes) + len(new_gt_boxes), gt_boxes.shape[1])\n",
    "    #points.reshape(len(points) + len(new_points), points.shape[1])\n",
    "\n",
    "    gt_boxes = np.append(gt_boxes, new_gt_boxes, axis=0)\n",
    "    points = np.append(points, new_points, axis=0)\n",
    "\n",
    "    print(gt_boxes.shape)\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3, 8)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3,8) into shape (1,8)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-ac0ec7e3e019>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moversampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moversampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moversampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshow_pc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moversampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (3,8) into shape (1,8)"
     ]
    }
   ],
   "source": [
    "oversampled = deepcopy(data_dict_list[1])\n",
    "new_data = deepcopy(data_dict_list[2])\n",
    "oversampled['gt_boxes'][0], oversampled['points'][:,1:] = oversample(oversampled['gt_boxes'][0], oversampled['points'][:, 1:], new_data['gt_boxes'][0], new_data['points'][:, 1:])\n",
    "\n",
    "show_pc(oversampled)\n",
    "mlab.savefig('figs/oversample.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}