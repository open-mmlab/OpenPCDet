{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitbe64631982d24ffbb2f77ea698e3ac22",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# KITTI Dataset augmentation visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Dataset structure\n",
    "\n",
    "```\n",
    "ðŸ“¦gta\n",
    "â”— ðŸ“‚training\n",
    "  â”£ ðŸ“‚calib\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.txt\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”£ ðŸ“‚image_2\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.png\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”£ ðŸ“‚label_2\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.txt\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”— ðŸ“‚velodyne\n",
    "    â”£ ðŸ“œ<file_id>.bin\n",
    "    â”— ðŸ“œ ...\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Notebook initialized with ipy backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mayavi.mlab as mlab\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import pcdet.datasets.augmentor\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.utils import common_utils\n",
    "from tools.visual_utils import visualize_utils as V\n",
    "\n",
    "mlab.init_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate pickles from the kitti data\n",
    "# os.system(\"python -m pcdet.datasets.kitti.kitti_dataset create_kitti_infos tools/cfgs/dataset_configs/kitti_dataset.yaml\")"
   ]
  },
  {
   "source": [
    "## Visualizing the LiDAR point cloud with labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = common_utils.create_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-12 18:01:49,568   INFO  Loading KITTI dataset\n",
      "2021-04-12 18:01:49,571   INFO  Total samples for KITTI dataset: 6\n",
      "2021-04-12 18:01:49,572   INFO  Total number of samples: \t6\n",
      "2021-04-12 18:01:49,573   INFO  Loading samples\n",
      "2021-04-12 18:01:49,609   INFO  Loaded sample index: \t1\n",
      "2021-04-12 18:01:49,648   INFO  Loaded sample index: \t2\n",
      "2021-04-12 18:01:49,699   INFO  Loaded sample index: \t3\n",
      "2021-04-12 18:01:49,728   INFO  Loaded sample index: \t4\n",
      "2021-04-12 18:01:49,762   INFO  Loaded sample index: \t5\n",
      "2021-04-12 18:01:49,783   INFO  Loaded sample index: \t6\n"
     ]
    }
   ],
   "source": [
    "cfg_from_yaml_file('tools/cfgs/dataset_configs/kitti_dataset.yaml', cfg)\n",
    "# cfg_from_yaml_file('tools/cfgs/kitti_models/pointpillar_augs.yaml', cfg)\n",
    "\n",
    "cfg.DATA_PATH = 'data/kitti'\n",
    "\n",
    "train_set, train_loader, train_sampler = build_dataloader(\n",
    "    dataset_cfg=cfg,\n",
    "    class_names=['Car', 'Pedestrian', 'Cyclist'],\n",
    "    batch_size=1,\n",
    "    dist=False,\n",
    "    workers=4,\n",
    "    logger=logger,\n",
    "    training=False,\n",
    "    merge_all_iters_to_one_epoch=False,\n",
    "    total_epochs=0\n",
    ")\n",
    "\n",
    "logger.info(f'Total number of samples: \\t{len(train_set)}')\n",
    "\n",
    "data_dict_list = []\n",
    "logger.info('Loading samples')\n",
    "for idx, data_dict in enumerate(train_set):\n",
    "    logger.info(f'Loaded sample index: \\t{idx + 1}')\n",
    "    data_dict = train_set.collate_batch([data_dict])\n",
    "    data_dict_list.append(data_dict)\n",
    "    if idx > 4: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 1, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data_dict_list[2]['gt_boxes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pc(data_dict):\n",
    "    V.draw_scenes(\n",
    "        points=data_dict['points'][:, 1:], gt_boxes=data_dict['gt_boxes'][0]\n",
    "    )\n",
    "\n",
    "    return mlab.test_plot3d()\n"
   ]
  },
  {
   "source": [
    "## Visualizing the original scene\n",
    "![Original Camera Image](data/kitti/training/image_2/000004.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4f77d303f2645878d89f3fc07bac3ba"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "show_pc(data_dict_list[1])\n",
    "#mlab.savefig('figs/aug_pipeline_output.png')\n",
    "#mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "## Augmentation methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Random flip"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip_along_x(gt_boxes, points):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C)\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    enable = True\n",
    "    if enable:\n",
    "        gt_boxes[:, 1] = -gt_boxes[:, 1]\n",
    "        gt_boxes[:, 6] = -gt_boxes[:, 6]\n",
    "        points[:, 1] = -points[:, 1]\n",
    "\n",
    "        if gt_boxes.shape[1] > 8:\n",
    "            gt_boxes[:, 8] = -gt_boxes[:, 8]\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def random_flip_along_y(gt_boxes, points):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C)\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    enable = True\n",
    "    if enable:\n",
    "        gt_boxes[:, 0] = -gt_boxes[:, 0]\n",
    "        gt_boxes[:, 6] = -(gt_boxes[:, 6] + np.pi)\n",
    "        points[:, 0] = -points[:, 0]\n",
    "\n",
    "        if gt_boxes.shape[1] > 7:\n",
    "            gt_boxes[:, 7] = -gt_boxes[:, 7]\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f129e844e284f16910adc2c16edf324"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "flipped_y = deepcopy(data_dict_list[1])\n",
    "flipped_y['gt_boxes'][0], flipped_y['points'][:,1:] = random_flip_along_y(flipped_y['gt_boxes'][0], flipped_y['points'][:,1:])\n",
    "\n",
    "show_pc(flipped_y)\n",
    "mlab.savefig('figs/flipped_y.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c06abba18e6403eab7eba95e5691f2c"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "flipped_x = deepcopy(data_dict_list[1])\n",
    "flipped_x['gt_boxes'][0], flipped_x['points'][:,1:] = random_flip_along_x(flipped_x['gt_boxes'][0], flipped_x['points'][:,1:])\n",
    "\n",
    "show_pc(flipped_x)\n",
    "mlab.savefig('figs/flipped_x.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "### Global rotation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_rotation(gt_boxes, points, rot_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        rot_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    noise_rotation = np.random.uniform(rot_range[0], rot_range[1])\n",
    "    points = common_utils.rotate_points_along_z(points[np.newaxis, :, :], np.array([noise_rotation]))[0]\n",
    "    gt_boxes[:, 0:3] = common_utils.rotate_points_along_z(gt_boxes[np.newaxis, :, 0:3], np.array([noise_rotation]))[0]\n",
    "    gt_boxes[:, 6] += noise_rotation\n",
    "    if gt_boxes.shape[1] > 8:\n",
    "        gt_boxes[:, 7:9] = common_utils.rotate_points_along_z(\n",
    "            np.hstack((gt_boxes[:, 7:9], np.zeros((gt_boxes.shape[0], 1))))[np.newaxis, :, :],\n",
    "            np.array([noise_rotation])\n",
    "        )[0][:, 0:2]\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0d4ad4144054f209a303ffcc98dd32e"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "rotated = deepcopy(data_dict_list[1])\n",
    "rotated['gt_boxes'][0], rotated['points'][:,1:] = global_rotation(rotated['gt_boxes'][0], rotated['points'][:,1:], [-0.78539816, 0.78539816])\n",
    "\n",
    "show_pc(rotated)\n",
    "mlab.savefig('figs/rotated_global.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "### Global scaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_scaling(gt_boxes, points, scale_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading]\n",
    "        points: (M, 3 + C),\n",
    "        scale_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if scale_range[1] - scale_range[0] < 1e-3:\n",
    "        return gt_boxes, points\n",
    "    noise_scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "    points[:, :3] *= noise_scale\n",
    "    gt_boxes[:, :6] *= noise_scale\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6983186f7c794d7ca3889a9fcbed90ae"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "scaled = deepcopy(data_dict_list[1])\n",
    "scaled['gt_boxes'][0], scaled['points'][:,1:] = global_scaling(scaled['gt_boxes'][0], scaled['points'][:, 1:], [0.2, 0.5])\n",
    "\n",
    "show_pc(scaled)\n",
    "mlab.savefig('figs/scaled_global.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "### Global translation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_translation_along_x(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "\n",
    "    points[:, 0] += offset\n",
    "    gt_boxes[:, 0] += offset\n",
    "\n",
    "    if gt_boxes.shape[1] > 7:\n",
    "        gt_boxes[:, 7] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def random_translation_along_y(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "\n",
    "    points[:, 1] += offset\n",
    "    gt_boxes[:, 1] += offset\n",
    "\n",
    "    if gt_boxes.shape[1] > 8:\n",
    "        gt_boxes[:, 8] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def random_translation_along_z(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "\n",
    "    points[:, 2] += offset\n",
    "    gt_boxes[:, 2] += offset\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8543fda372fb4ceeb8428367ee8b1d05"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "translation_x = deepcopy(data_dict_list[1])\n",
    "translation_x['gt_boxes'][0], translation_x['points'][:,1:] = random_translation_along_x(translation_x['gt_boxes'][0], translation_x['points'][:, 1:], [15, 20])\n",
    "\n",
    "show_pc(translation_x)\n",
    "mlab.savefig('figs/translation_global_x.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d99e896ebb7488abb9f79fcda3c0c13"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "translation_y = deepcopy(data_dict_list[1])\n",
    "translation_y['gt_boxes'][0], translation_y['points'][:,1:] = random_translation_along_y(translation_y['gt_boxes'][0], translation_y['points'][:, 1:], [15, 20])\n",
    "\n",
    "show_pc(translation_y)\n",
    "mlab.savefig('figs/translation_global_y.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c7e87408ea3430eb98beadfb6ce3057"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "translation_z = deepcopy(data_dict_list[1])\n",
    "translation_z['gt_boxes'][0], translation_z['points'][:,1:] = random_translation_along_z(translation_z['gt_boxes'][0], translation_z['points'][:, 1:], [15, 20])\n",
    "\n",
    "show_pc(translation_z)\n",
    "mlab.savefig('figs/translation_global_z.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "#### Aux function to find which points are inside a bounding box"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points_in_box(points, gt_box):\n",
    "    x, y, z, dx, dy, dz = gt_box[0], gt_box[1], gt_box[2], gt_box[3], gt_box[4], gt_box[5]\n",
    "\n",
    "    points = points[np.logical_and(points[:,0] <= x + dx/2, points[:,0] >= x - dx/2)] \n",
    "    points = points[np.logical_and(points[:,1] <= y + dy/2, points[:,1] >= y - dy/2)] \n",
    "    points[np.logical_and(points[:,2] <= z + dz/2, points[:,2] >= z - dz/2)]\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb3d27847b3b4d75a0b11f7e37e45f43"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "points_to_filter = deepcopy(data_dict_list[1])\n",
    "filtered_points = get_points_in_box(points_to_filter['points'][:,1:], points_to_filter['gt_boxes'][0][1])\n",
    "\n",
    "V.draw_scenes(\n",
    "        points=filtered_points, gt_boxes=points_to_filter['gt_boxes'][0,1:]\n",
    "    )\n",
    "\n",
    "mlab.savefig('figs/points_in_box.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "### Local translation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_translation_along_x(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    for idx, box in enumerate(gt_boxes):\n",
    "        offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "        points_in_box = get_points_in_box(points, box)\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                point[0] += offset\n",
    "\n",
    "        gt_boxes[idx, 0] += offset\n",
    "\n",
    "        if gt_boxes.shape[1] > 7:\n",
    "            gt_boxes[idx, 7] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "\n",
    "def local_translation_along_y(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    for idx, box in enumerate(gt_boxes):\n",
    "        offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "        points_in_box = get_points_in_box(points, box)\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                point[1] += offset\n",
    "\n",
    "        gt_boxes[idx, 1] += offset\n",
    "\n",
    "        if gt_boxes.shape[1] > 8:\n",
    "            gt_boxes[idx, 8] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "\n",
    "def local_translation_along_z(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    for idx, box in enumerate(gt_boxes):\n",
    "        offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "        points_in_box = get_points_in_box(points, box)\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                point[2] += offset\n",
    "\n",
    "        gt_boxes[idx, 2] += offset\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c431a90f8cb45cd985c98b6662c2e84"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "local_translation_x = deepcopy(data_dict_list[1])\n",
    "local_translation_x['gt_boxes'][0], local_translation_x['points'][:,1:] = local_translation_along_x(local_translation_x['gt_boxes'][0], local_translation_x['points'][:, 1:], [10, 15])\n",
    "\n",
    "show_pc(local_translation_x)\n",
    "mlab.savefig('figs/translation_local_x.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "604837abdd474bc9a9025e7c139eccf7"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "local_translation_y = deepcopy(data_dict_list[1])\n",
    "local_translation_y['gt_boxes'][0], local_translation_y['points'][:,1:] = local_translation_along_y(local_translation_y['gt_boxes'][0], local_translation_y['points'][:, 1:], [10, 15])\n",
    "\n",
    "show_pc(local_translation_y)\n",
    "mlab.savefig('figs/translation_local_y.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "969ad233b20c4ea5a8aec8932431f1e6"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "local_translation_z = deepcopy(data_dict_list[1])\n",
    "local_translation_z['gt_boxes'][0], local_translation_z['points'][:,1:] = local_translation_along_z(local_translation_z['gt_boxes'][0], local_translation_z['points'][:, 1:], [10, 15])\n",
    "\n",
    "show_pc(local_translation_z)\n",
    "mlab.savefig('figs/translation_local_z.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "### Local scaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_scaling(gt_boxes, points, scale_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading]\n",
    "        points: (M, 3 + C),\n",
    "        scale_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if scale_range[1] - scale_range[0] < 1e-3:\n",
    "        return gt_boxes, points\n",
    "\n",
    "    noise_scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "    for idx, box in enumerate(gt_boxes):\n",
    "        noise_scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "        points_in_box = get_points_in_box(points, box)\n",
    "\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                # tranlation to axis center\n",
    "                point[0] -= box[0]\n",
    "                point[1] -= box[1]\n",
    "                point[2] -= box[2]\n",
    "\n",
    "                # apply scaling\n",
    "                point[:3] *= noise_scale\n",
    "\n",
    "                # tranlation back to original position\n",
    "                point[0] += box[0]\n",
    "                point[1] += box[1]\n",
    "                point[2] += box[2]\n",
    "\n",
    "        gt_boxes[idx, 3:6] *= noise_scale\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa53af7f1d6f4d46b8d5380d53277783"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "scaled_local = deepcopy(data_dict_list[1])\n",
    "scaled_local['gt_boxes'][0], scaled_local['points'][:,1:] = local_scaling(scaled_local['gt_boxes'][0], scaled_local['points'][:, 1:], [0.2, 0.5])\n",
    "\n",
    "show_pc(scaled_local)\n",
    "mlab.savefig('figs/scaled_local.png')\n",
    "mlab.test_plot3d()"
   ]
  },
  {
   "source": [
    "### Local rotation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_rotation(gt_boxes, points, rot_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        rot_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx, box in enumerate(gt_boxes):\n",
    "        noise_rotation = np.random.uniform(rot_range[0], rot_range[1])\n",
    "        points_in_box = get_points_in_box(points, box)\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                centroid_x = box[0]\n",
    "                centroid_y = box[1]\n",
    "                centroid_z = box[2]\n",
    "\n",
    "                # tranlation to axis center\n",
    "                point[0] -= centroid_x\n",
    "                point[1] -= centroid_y\n",
    "                point[2] -= centroid_z\n",
    "                box[0] -= centroid_x\n",
    "                box[1] -= centroid_y\n",
    "                box[2] -= centroid_z\n",
    "\n",
    "                # apply rotation\n",
    "                point[:] = common_utils.rotate_points_along_z(point[np.newaxis, np.newaxis, :], np.array([noise_rotation]))[0][0]\n",
    "                box[0:3] = common_utils.rotate_points_along_z(box[np.newaxis, np.newaxis, 0:3], np.array([noise_rotation]))[0][0]\n",
    "\n",
    "                # tranlation back to original position\n",
    "                point[0] += centroid_x\n",
    "                point[1] += centroid_y\n",
    "                point[2] += centroid_z\n",
    "                box[0] += centroid_x\n",
    "                box[1] += centroid_y\n",
    "                box[2] += centroid_z\n",
    "\n",
    "        gt_boxes[idx, 6] += noise_rotation\n",
    "        if gt_boxes.shape[1] > 8:\n",
    "            gt_boxes[idx, 7:9] = common_utils.rotate_points_along_z(\n",
    "                np.hstack((gt_boxes[idx, 7:9], np.zeros((gt_boxes.shape[0], 1))))[np.newaxis, :, :],\n",
    "                np.array([noise_rotation])\n",
    "            )[0][:, 0:2]\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd4c25f29a194b29953e18a322cdd38c"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "rotated_local = deepcopy(data_dict_list[1])\n",
    "rotated_local['gt_boxes'][0], rotated_local['points'][:,1:] = local_rotation(rotated_local['gt_boxes'][0],rotated_local['points'][:, 1:], [-0.78539815, 0.78539816])\n",
    "\n",
    "show_pc(rotated_local)\n",
    "mlab.savefig('figs/rotated_local.png')\n",
    "mlab.test_plot3d()"
   ]
  }
 ]
}