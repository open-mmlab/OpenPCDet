{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitbe64631982d24ffbb2f77ea698e3ac22",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# KITTI Dataset augmentation visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Dataset structure\n",
    "\n",
    "```\n",
    "ðŸ“¦gta\n",
    "â”— ðŸ“‚training\n",
    "  â”£ ðŸ“‚calib\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.txt\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”£ ðŸ“‚image_2\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.png\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”£ ðŸ“‚label_2\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.txt\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”— ðŸ“‚velodyne\n",
    "    â”£ ðŸ“œ<file_id>.bin\n",
    "    â”— ðŸ“œ ...\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Notebook initialized with ipy backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mayavi.mlab as mlab\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import pcdet.datasets.augmentor\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.utils import common_utils\n",
    "from tools.visual_utils import visualize_utils as V\n",
    "\n",
    "mlab.init_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# generate pickles from the kitti data\n",
    "os.system(\"python -m pcdet.datasets.kitti.kitti_dataset create_kitti_infos tools/cfgs/dataset_configs/kitti_dataset.yaml\")"
   ]
  },
  {
   "source": [
    "## Visualizing the LiDAR point cloud with labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = common_utils.create_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-05 16:17:19,814   INFO  Loading KITTI dataset\n",
      "2021-04-05 16:17:19,814   INFO  Loading KITTI dataset\n",
      "2021-04-05 16:17:19,816   INFO  Total samples for KITTI dataset: 6\n",
      "2021-04-05 16:17:19,816   INFO  Total samples for KITTI dataset: 6\n",
      "2021-04-05 16:17:19,817   INFO  Total number of samples: \t6\n",
      "2021-04-05 16:17:19,817   INFO  Total number of samples: \t6\n",
      "2021-04-05 16:17:19,818   INFO  Loading samples\n",
      "2021-04-05 16:17:19,818   INFO  Loading samples\n",
      "2021-04-05 16:17:19,833   INFO  Loaded sample index: \t1\n",
      "2021-04-05 16:17:19,833   INFO  Loaded sample index: \t1\n",
      "2021-04-05 16:17:19,879   INFO  Loaded sample index: \t2\n",
      "2021-04-05 16:17:19,879   INFO  Loaded sample index: \t2\n",
      "2021-04-05 16:17:19,899   INFO  Loaded sample index: \t3\n",
      "2021-04-05 16:17:19,899   INFO  Loaded sample index: \t3\n",
      "2021-04-05 16:17:19,916   INFO  Loaded sample index: \t4\n",
      "2021-04-05 16:17:19,916   INFO  Loaded sample index: \t4\n",
      "2021-04-05 16:17:19,933   INFO  Loaded sample index: \t5\n",
      "2021-04-05 16:17:19,933   INFO  Loaded sample index: \t5\n",
      "2021-04-05 16:17:19,951   INFO  Loaded sample index: \t6\n",
      "2021-04-05 16:17:19,951   INFO  Loaded sample index: \t6\n"
     ]
    }
   ],
   "source": [
    "cfg_from_yaml_file('tools/cfgs/dataset_configs/kitti_dataset.yaml', cfg)\n",
    "\n",
    "cfg.DATA_PATH = 'data/kitti'\n",
    "\n",
    "train_set, train_loader, train_sampler = build_dataloader(\n",
    "    dataset_cfg=cfg,\n",
    "    class_names=['Car', 'Pedestrian', 'Cyclist'],\n",
    "    batch_size=1,\n",
    "    dist=False,\n",
    "    workers=4,\n",
    "    logger=logger,\n",
    "    training=False,\n",
    "    merge_all_iters_to_one_epoch=False,\n",
    "    total_epochs=0\n",
    ")\n",
    "\n",
    "logger.info(f'Total number of samples: \\t{len(train_set)}')\n",
    "\n",
    "data_dict_list = []\n",
    "logger.info('Loading samples')\n",
    "for idx, data_dict in enumerate(train_set):\n",
    "    logger.info(f'Loaded sample index: \\t{idx + 1}')\n",
    "    data_dict = train_set.collate_batch([data_dict])\n",
    "    data_dict_list.append(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pc(data_dict):\n",
    "    V.draw_scenes(\n",
    "        points=data_dict['points'][:, 1:], gt_boxes=data_dict['gt_boxes'][0]\n",
    "    )\n",
    "    return mlab.test_plot3d()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93da7ec9f7894f799d8c2394ecc7c8df"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "show_pc(data_dict_list[1])"
   ]
  },
  {
   "source": [
    "## Augmentation methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Random flip"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip_along_x(gt_boxes, points):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C)\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    enable = True\n",
    "    if enable:\n",
    "        gt_boxes[:, 1] = -gt_boxes[:, 1]\n",
    "        gt_boxes[:, 6] = -gt_boxes[:, 6]\n",
    "        points[:, 1] = -points[:, 1]\n",
    "\n",
    "        if gt_boxes.shape[1] > 8:\n",
    "            gt_boxes[:, 8] = -gt_boxes[:, 8]\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def random_flip_along_y(gt_boxes, points):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C)\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    enable = True\n",
    "    if enable:\n",
    "        gt_boxes[:, 0] = -gt_boxes[:, 0]\n",
    "        gt_boxes[:, 6] = -(gt_boxes[:, 6] + np.pi)\n",
    "        points[:, 0] = -points[:, 0]\n",
    "\n",
    "        if gt_boxes.shape[1] > 7:\n",
    "            gt_boxes[:, 7] = -gt_boxes[:, 7]\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e92ccda6350147a0bfe447c659cf16a1"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "flipped_y = deepcopy(data_dict_list[1])\n",
    "flipped_y['gt_boxes'][0], flipped_y['points'][:,1:] = random_flip_along_y(flipped_y['gt_boxes'][0], flipped_y['points'][:,1:])\n",
    "\n",
    "show_pc(flipped_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2c642c5ff924334ae3ab6220684d7c3"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "flipped_x = deepcopy(data_dict_list[1])\n",
    "flipped_x['gt_boxes'][0], flipped_x['points'][:,1:] = random_flip_along_x(flipped_x['gt_boxes'][0], flipped_x['points'][:,1:])\n",
    "\n",
    "show_pc(flipped_x)"
   ]
  },
  {
   "source": [
    "### Global rotation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_rotation(gt_boxes, points, rot_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        rot_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    noise_rotation = np.random.uniform(rot_range[0], rot_range[1])\n",
    "    points = common_utils.rotate_points_along_z(points[np.newaxis, :, :], np.array([noise_rotation]))[0]\n",
    "    gt_boxes[:, 0:3] = common_utils.rotate_points_along_z(gt_boxes[np.newaxis, :, 0:3], np.array([noise_rotation]))[0]\n",
    "    gt_boxes[:, 6] += noise_rotation\n",
    "    if gt_boxes.shape[1] > 8:\n",
    "        gt_boxes[:, 7:9] = common_utils.rotate_points_along_z(\n",
    "            np.hstack((gt_boxes[:, 7:9], np.zeros((gt_boxes.shape[0], 1))))[np.newaxis, :, :],\n",
    "            np.array([noise_rotation])\n",
    "        )[0][:, 0:2]\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ffe8a25014b74cd09027c85dbe83aafe"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "rotated = deepcopy(data_dict_list[1])\n",
    "rotated['gt_boxes'][0], rotated['points'][:,1:] = global_rotation(rotated['gt_boxes'][0], rotated['points'][:,1:], [-0.78539816, 0.78539816])\n",
    "\n",
    "show_pc(rotated)"
   ]
  },
  {
   "source": [
    "### Global scaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_scaling(gt_boxes, points, scale_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading]\n",
    "        points: (M, 3 + C),\n",
    "        scale_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if scale_range[1] - scale_range[0] < 1e-3:\n",
    "        return gt_boxes, points\n",
    "    noise_scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "    points[:, :3] *= noise_scale\n",
    "    gt_boxes[:, :6] *= noise_scale\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d006ed4aaf3840448aa268e913c344c1"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "scaled = deepcopy(data_dict_list[1])\n",
    "scaled['gt_boxes'][0], scaled['points'][:,1:] = global_scaling(scaled['gt_boxes'][0], scaled['points'][:, 1:], [0.2, 0.5])\n",
    "\n",
    "show_pc(scaled)"
   ]
  },
  {
   "source": [
    "### Global translation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_translation_along_x(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "\n",
    "    points[:, 0] += offset\n",
    "    gt_boxes[:, 0] += offset\n",
    "\n",
    "    if gt_boxes.shape[1] > 7:\n",
    "        gt_boxes[:, 7] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def random_translation_along_y(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "\n",
    "    points[:, 1] += offset\n",
    "    gt_boxes[:, 1] += offset\n",
    "\n",
    "    if gt_boxes.shape[1] > 8:\n",
    "        gt_boxes[:, 8] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def random_translation_along_z(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "\n",
    "    points[:, 2] += offset\n",
    "    gt_boxes[:, 2] += offset\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c398b267273e45d1a27a8ed3c1178d45"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "translation_x = deepcopy(data_dict_list[1])\n",
    "translation_x['gt_boxes'][0], translation_x['points'][:,1:] = random_translation_along_x(translation_x['gt_boxes'][0], translation_x['points'][:, 1:], [15, 20])\n",
    "\n",
    "show_pc(translation_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f281313e711b4c2aaccc71b048511781"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "translation_y = deepcopy(data_dict_list[1])\n",
    "translation_y['gt_boxes'][0], translation_y['points'][:,1:] = random_translation_along_y(translation_y['gt_boxes'][0], translation_y['points'][:, 1:], [15, 20])\n",
    "\n",
    "show_pc(translation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a24f05cdfe64ef6aa734c420df2f6c4"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "translation_z = deepcopy(data_dict_list[1])\n",
    "translation_z['gt_boxes'][0], translation_z['points'][:,1:] = random_translation_along_z(translation_z['gt_boxes'][0], translation_z['points'][:, 1:], [15, 20])\n",
    "\n",
    "show_pc(translation_z)"
   ]
  },
  {
   "source": [
    "#### Aux function to find which points are inside a bounding box"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_points_in_box(points, gt_box):\n",
    "    filter_arr = []\n",
    "    for point in points:\n",
    "        x, y, z, dx, dy, dz = gt_box[0], gt_box[1], gt_box[2], gt_box[3], gt_box[4], gt_box[5]\n",
    "        if point[0] <= x + dx/2 and point[0] >= x - dx/2 \\\n",
    "            and point[1] <= y + dy/2 and point[1] >= y - dy/2 \\\n",
    "                and point[2] <= z + dz/2 and point[2] >= z - dz/2:\n",
    "                    filter_arr.append(True)\n",
    "        else:\n",
    "            filter_arr.append(False)\n",
    "\n",
    "    # points_in_box = points[filter_arr]\n",
    "    return filter_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba3126b5683e4a01a333cda7c4694662"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "points_to_filter = deepcopy(data_dict_list[1])\n",
    "filter_arr = filter_points_in_box(points_to_filter['points'][:,1:], points_to_filter['gt_boxes'][0][1])\n",
    "filtered_points = points_to_filter['points'][:,1:][filter_arr]\n",
    "\n",
    "V.draw_scenes(\n",
    "        points=filtered_points, gt_boxes=points_to_filter['gt_boxes'][0,1:]\n",
    "    )"
   ]
  },
  {
   "source": [
    "### Local translation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_translation_along_x(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "\n",
    "    for box in gt_boxes:\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                point[0] += offset\n",
    "\n",
    "    gt_boxes[:, 0] += offset\n",
    "\n",
    "    if gt_boxes.shape[1] > 7:\n",
    "        gt_boxes[:, 7] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "\n",
    "def local_translation_along_y(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "\n",
    "    for box in gt_boxes:\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                point[1] += offset\n",
    "\n",
    "    gt_boxes[:, 1] += offset\n",
    "\n",
    "    if gt_boxes.shape[1] > 8:\n",
    "        gt_boxes[:, 8] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "\n",
    "def local_translation_along_z(gt_boxes, points, offset_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset_range: [min max]]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    offset = np.random.uniform(offset_range[0], offset_range[1])\n",
    "\n",
    "    for box in gt_boxes:\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                point[2] += offset\n",
    "\n",
    "    gt_boxes[:, 2] += offset\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9be515417ff54cf9951ddcab4521c05a"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "local_translation_x = deepcopy(data_dict_list[1])\n",
    "local_translation_x['gt_boxes'][0], local_translation_x['points'][:,1:] = local_translation_along_x(local_translation_x['gt_boxes'][0], local_translation_x['points'][:, 1:], [10, 15])\n",
    "\n",
    "show_pc(local_translation_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b2a675560524ad8aa19cf3da3efbe23"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "local_translation_y = deepcopy(data_dict_list[1])\n",
    "local_translation_y['gt_boxes'][0], local_translation_y['points'][:,1:] = local_translation_along_y(local_translation_y['gt_boxes'][0], local_translation_y['points'][:, 1:], [10, 15])\n",
    "\n",
    "show_pc(local_translation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3343b6194ee646a5b0e53cbc1d26f3dd"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "local_translation_z = deepcopy(data_dict_list[1])\n",
    "local_translation_z['gt_boxes'][0], local_translation_z['points'][:,1:] = local_translation_along_z(local_translation_z['gt_boxes'][0], local_translation_z['points'][:, 1:], [10, 15])\n",
    "\n",
    "show_pc(local_translation_z)"
   ]
  },
  {
   "source": [
    "### Local scaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_scaling(gt_boxes, points, scale_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading]\n",
    "        points: (M, 3 + C),\n",
    "        scale_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if scale_range[1] - scale_range[0] < 1e-3:\n",
    "        return gt_boxes, points\n",
    "\n",
    "    noise_scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "    for box in gt_boxes:\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                # tranlation to axis center\n",
    "                point[0] -= box[0]\n",
    "                point[1] -= box[1]\n",
    "                point[2] -= box[2]\n",
    "\n",
    "                # apply scaling\n",
    "                point[:3] *= noise_scale\n",
    "\n",
    "                # tranlation back to original position\n",
    "                point[0] += box[0]\n",
    "                point[1] += box[1]\n",
    "                point[2] += box[2]\n",
    "\n",
    "    gt_boxes[:, 3:6] *= noise_scale\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6703e207cb93435cbb7dc216a6ebabb1"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "scaled_local = deepcopy(data_dict_list[1])\n",
    "scaled_local['gt_boxes'][0], scaled_local['points'][:,1:] = local_scaling(scaled_local['gt_boxes'][0], scaled_local['points'][:, 1:], [1.2, 1.5])\n",
    "\n",
    "show_pc(scaled_local)"
   ]
  },
  {
   "source": [
    "### Local rotation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_rotation(gt_boxes, points, rot_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        rot_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    noise_rotation = np.random.uniform(rot_range[0], rot_range[1])\n",
    "\n",
    "    for box in gt_boxes:\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                centroid_x = box[0]\n",
    "                centroid_y = box[1]\n",
    "                centroid_z = box[2]\n",
    "\n",
    "                #print(\"BEFORE:\\n\" + str(point))\n",
    "                # tranlation to axis center\n",
    "                point[0] -= centroid_x\n",
    "                point[1] -= centroid_y\n",
    "                point[2] -= centroid_z\n",
    "                box[0] -= centroid_x\n",
    "                box[1] -= centroid_y\n",
    "                box[2] -= centroid_z\n",
    "\n",
    "                # apply rotation\n",
    "                point[:] = common_utils.rotate_points_along_z(point[np.newaxis, np.newaxis, :], np.array([noise_rotation]))[0][0]\n",
    "                box[0:3] = common_utils.rotate_points_along_z(box[np.newaxis, np.newaxis, 0:3], np.array([noise_rotation]))[0][0]\n",
    "\n",
    "                # tranlation back to original position\n",
    "                point[0] += centroid_x\n",
    "                point[1] += centroid_y\n",
    "                point[2] += centroid_z\n",
    "                box[0] += centroid_x\n",
    "                box[1] += centroid_y\n",
    "                box[2] += centroid_z\n",
    "                #print(\"AFTER:\\n\" + str(point))\n",
    "\n",
    "    gt_boxes[:, 6] += noise_rotation\n",
    "    if gt_boxes.shape[1] > 8:\n",
    "        gt_boxes[:, 7:9] = common_utils.rotate_points_along_z(\n",
    "            np.hstack((gt_boxes[:, 7:9], np.zeros((gt_boxes.shape[0], 1))))[np.newaxis, :, :],\n",
    "            np.array([noise_rotation])\n",
    "        )[0][:, 0:2]\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11349f54868b408d83431eda9a082ac5"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "rotated_local = deepcopy(data_dict_list[1])\n",
    "rotated_local['gt_boxes'][0], rotated_local['points'][:,1:] = local_rotation(rotated_local['gt_boxes'][0],rotated_local['points'][:, 1:], [0.78539815, 0.78539816])\n",
    "\n",
    "show_pc(rotated_local)"
   ]
  },
  {
   "source": [
    "Oversampling (TODO)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(gt_boxes, points, new_gt_boxes, new_points):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    #gt_boxes.reshape(len(gt_boxes) + len(new_gt_boxes), gt_boxes.shape[1])\n",
    "    #points.reshape(len(points) + len(new_points), points.shape[1])\n",
    "\n",
    "    gt_boxes = np.append(gt_boxes, new_gt_boxes, axis=0)\n",
    "    points = np.append(points, new_points, axis=0)\n",
    "\n",
    "    print(gt_boxes.shape)\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3, 8)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3,8) into shape (2,8)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-b6deb02bdf83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moversampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moversampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moversampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moversampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshow_pc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moversampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (3,8) into shape (2,8)"
     ]
    }
   ],
   "source": [
    "oversampled = deepcopy(data_dict_list[1])\n",
    "new_data = deepcopy(data_dict_list[2])\n",
    "oversampled['gt_boxes'][0], oversampled['points'][:,1:] = oversample(oversampled['gt_boxes'][0], oversampled['points'][:, 1:], new_data['gt_boxes'][0], new_data['points'][:, 1:])\n",
    "\n",
    "show_pc(oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}