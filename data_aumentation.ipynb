{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitbe64631982d24ffbb2f77ea698e3ac22",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# KITTI Dataset augmentation visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Dataset structure\n",
    "\n",
    "```\n",
    "ðŸ“¦gta\n",
    "â”— ðŸ“‚training\n",
    "  â”£ ðŸ“‚calib\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.txt\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”£ ðŸ“‚image_2\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.png\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”£ ðŸ“‚label_2\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.txt\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”— ðŸ“‚velodyne\n",
    "    â”£ ðŸ“œ<file_id>.bin\n",
    "    â”— ðŸ“œ ...\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Notebook initialized with ipy backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mayavi.mlab as mlab\n",
    "import numpy as np\n",
    "\n",
    "import pcdet.datasets.augmentor\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.utils import common_utils\n",
    "from tools.visual_utils import visualize_utils as V\n",
    "\n",
    "mlab.init_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# generate pickles from the kitti data\n",
    "os.system(\"python -m pcdet.datasets.kitti.kitti_dataset create_kitti_infos tools/cfgs/dataset_configs/kitti_dataset.yaml\")"
   ]
  },
  {
   "source": [
    "## Visualizing the LiDAR point cloud with labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = common_utils.create_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-03-31 17:03:12,629   INFO  Loading KITTI dataset\n",
      "2021-03-31 17:03:12,630   INFO  Total samples for KITTI dataset: 6\n",
      "2021-03-31 17:03:12,630   INFO  Total number of samples: \t6\n",
      "2021-03-31 17:03:12,674   INFO  Loaded sample index: \t1\n",
      "2021-03-31 17:03:12,699   INFO  Loaded sample index: \t2\n",
      "2021-03-31 17:03:12,725   INFO  Loaded sample index: \t3\n",
      "2021-03-31 17:03:12,740   INFO  Loaded sample index: \t4\n",
      "2021-03-31 17:03:12,765   INFO  Loaded sample index: \t5\n",
      "2021-03-31 17:03:12,789   INFO  Loaded sample index: \t6\n"
     ]
    }
   ],
   "source": [
    "cfg_from_yaml_file('tools/cfgs/dataset_configs/kitti_dataset.yaml', cfg)\n",
    "\n",
    "cfg.DATA_PATH = 'data/kitti'\n",
    "\n",
    "train_set, train_loader, train_sampler = build_dataloader(\n",
    "    dataset_cfg=cfg,\n",
    "    class_names=['Car', 'Pedestrian', 'Cyclist'],\n",
    "    batch_size=1,\n",
    "    dist=False,\n",
    "    workers=4,\n",
    "    logger=logger,\n",
    "    training=False,\n",
    "    merge_all_iters_to_one_epoch=False,\n",
    "    total_epochs=0\n",
    ")\n",
    "\n",
    "logger.info(f'Total number of samples: \\t{len(train_set)}')\n",
    "\n",
    "data_dict_list = []\n",
    "logger.info('Loading samples')\n",
    "for idx, data_dict in enumerate(train_set):\n",
    "    logger.info(f'Loaded sample index: \\t{idx + 1}')\n",
    "    data_dict = train_set.collate_batch([data_dict])\n",
    "    data_dict_list.append(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pc(data_dict):\n",
    "    V.draw_scenes(\n",
    "        points=data_dict['points'][:, 1:], gt_boxes=data_dict['gt_boxes'][0]\n",
    "    )\n",
    "    return mlab.test_plot3d()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3682541ca45495c8d482a53e089f4a2"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "show_pc(data_dict_list[1])"
   ]
  },
  {
   "source": [
    "## Augmentation methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip_along_x(gt_boxes, points):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C)\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    enable = np.random.choice([False, True], replace=False, p=[0.5, 0.5])\n",
    "    if enable:\n",
    "        gt_boxes[:, 1] = -gt_boxes[:, 1]\n",
    "        gt_boxes[:, 6] = -gt_boxes[:, 6]\n",
    "        points[:, 1] = -points[:, 1]\n",
    "\n",
    "        if gt_boxes.shape[1] > 7:\n",
    "            gt_boxes[:, 8] = -gt_boxes[:, 8]\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def random_flip_along_y(gt_boxes, points):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C)\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    enable = np.random.choice([False, True], replace=False, p=[0.5, 0.5])\n",
    "    if enable:\n",
    "        gt_boxes[:, 0] = -gt_boxes[:, 0]\n",
    "        gt_boxes[:, 6] = -(gt_boxes[:, 6] + np.pi)\n",
    "        points[:, 0] = -points[:, 0]\n",
    "\n",
    "        if gt_boxes.shape[1] > 7:\n",
    "            gt_boxes[:, 7] = -gt_boxes[:, 7]\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32bdbf47ad2042e5b6348f5b385747ae"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "flipped_y = data_dict_list[1]\n",
    "flipped_y['gt_boxes'], flipped_y['points'] = random_flip_along_y(flipped_y['gt_boxes'], flipped_y['points'])\n",
    "\n",
    "show_pc(flipped_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_rotation(gt_boxes, points, rot_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        rot_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    noise_rotation = np.random.uniform(rot_range[0], rot_range[1])\n",
    "    points = common_utils.rotate_points_along_z(points[np.newaxis, :, :], np.array([noise_rotation]))[0]\n",
    "    gt_boxes[:, 0:3] = common_utils.rotate_points_along_z(gt_boxes[np.newaxis, :, 0:3], np.array([noise_rotation]))[0]\n",
    "    gt_boxes[:, 6] += noise_rotation\n",
    "    if gt_boxes.shape[1] > 7:\n",
    "        gt_boxes[:, 7:9] = common_utils.rotate_points_along_z(\n",
    "            np.hstack((gt_boxes[:, 7:9], np.zeros((gt_boxes.shape[0], 1))))[np.newaxis, :, :],\n",
    "            np.array([noise_rotation])\n",
    "        )[0][:, 0:2]\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Expected batch2_sizes[0] == bs && batch2_sizes[1] == contraction_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-f31afe0b41f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrotated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrotated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshow_pc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-be63ccad8fb3>\u001b[0m in \u001b[0;36mglobal_rotation\u001b[0;34m(gt_boxes, points, rot_range)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnoise_rotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrot_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate_points_along_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise_rotation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mgt_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate_points_along_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise_rotation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mgt_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnoise_rotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgt_boxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/thesis/OpenPCDet/pcdet/utils/common_utils.py\u001b[0m in \u001b[0;36mrotate_points_along_z\u001b[0;34m(points, angle)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     ), dim=1).view(-1, 3, 3).float()\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mpoints_rot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mpoints_rot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_rot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpoints_rot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_numpy\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpoints_rot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected batch2_sizes[0] == bs && batch2_sizes[1] == contraction_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    }
   ],
   "source": [
    "rotated = data_dict_list[1]\n",
    "rotated['gt_boxes'], rotated['points'] = global_rotation(rotated['gt_boxes'], rotated['points'], [10, 30])\n",
    "\n",
    "show_pc(rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_scaling(gt_boxes, points, scale_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading]\n",
    "        points: (M, 3 + C),\n",
    "        scale_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if scale_range[1] - scale_range[0] < 1e-3:\n",
    "        return gt_boxes, points\n",
    "    noise_scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "    points[:, :3] *= noise_scale\n",
    "    gt_boxes[:, :6] *= noise_scale\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Expected batch2_sizes[0] == bs && batch2_sizes[1] == contraction_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-77036b38f1ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'points'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshow_pc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-be63ccad8fb3>\u001b[0m in \u001b[0;36mglobal_rotation\u001b[0;34m(gt_boxes, points, rot_range)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mgt_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnoise_rotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgt_boxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         gt_boxes[:, 7:9] = common_utils.rotate_points_along_z(\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_boxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise_rotation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/thesis/OpenPCDet/pcdet/utils/common_utils.py\u001b[0m in \u001b[0;36mrotate_points_along_z\u001b[0;34m(points, angle)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     ), dim=1).view(-1, 3, 3).float()\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mpoints_rot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mpoints_rot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_rot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpoints_rot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_numpy\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpoints_rot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected batch2_sizes[0] == bs && batch2_sizes[1] == contraction_size to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    }
   ],
   "source": [
    "scaled = data_dict_list[1]\n",
    "scaled['gt_boxes'], scaled['points'] = global_rotation(scaled['gt_boxes'][0], scaled['points'][:, 1:], [2, 4])\n",
    "\n",
    "show_pc(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}