{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitbe64631982d24ffbb2f77ea698e3ac22",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# KITTI Dataset augmentation visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Dataset structure\n",
    "\n",
    "```\n",
    "ðŸ“¦gta\n",
    "â”— ðŸ“‚training\n",
    "  â”£ ðŸ“‚calib\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.txt\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”£ ðŸ“‚image_2\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.png\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”£ ðŸ“‚label_2\n",
    "  â”ƒ â”£ ðŸ“œ<file_id>.txt\n",
    "  â”ƒ â”— ðŸ“œ ...\n",
    "  â”— ðŸ“‚velodyne\n",
    "    â”£ ðŸ“œ<file_id>.bin\n",
    "    â”— ðŸ“œ ...\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Notebook initialized with ipy backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mayavi.mlab as mlab\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "import pcdet.datasets.augmentor\n",
    "\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.utils import common_utils\n",
    "from tools.visual_utils import visualize_utils as V\n",
    "\n",
    "mlab.init_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# generate pickles from the kitti data\n",
    "os.system(\"python -m pcdet.datasets.kitti.kitti_dataset create_kitti_infos tools/cfgs/dataset_configs/kitti_dataset.yaml\")"
   ]
  },
  {
   "source": [
    "## Visualizing the LiDAR point cloud with labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = common_utils.create_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-02 18:44:02,512   INFO  Loading KITTI dataset\n",
      "2021-04-02 18:44:02,513   INFO  Total samples for KITTI dataset: 6\n",
      "2021-04-02 18:44:02,514   INFO  Total number of samples: \t6\n",
      "2021-04-02 18:44:02,515   INFO  Loading samples\n",
      "2021-04-02 18:44:02,541   INFO  Loaded sample index: \t1\n",
      "2021-04-02 18:44:02,560   INFO  Loaded sample index: \t2\n",
      "2021-04-02 18:44:02,578   INFO  Loaded sample index: \t3\n",
      "2021-04-02 18:44:02,593   INFO  Loaded sample index: \t4\n",
      "2021-04-02 18:44:02,609   INFO  Loaded sample index: \t5\n",
      "2021-04-02 18:44:02,630   INFO  Loaded sample index: \t6\n"
     ]
    }
   ],
   "source": [
    "cfg_from_yaml_file('tools/cfgs/dataset_configs/kitti_dataset.yaml', cfg)\n",
    "\n",
    "cfg.DATA_PATH = 'data/kitti'\n",
    "\n",
    "train_set, train_loader, train_sampler = build_dataloader(\n",
    "    dataset_cfg=cfg,\n",
    "    class_names=['Car', 'Pedestrian', 'Cyclist'],\n",
    "    batch_size=1,\n",
    "    dist=False,\n",
    "    workers=4,\n",
    "    logger=logger,\n",
    "    training=False,\n",
    "    merge_all_iters_to_one_epoch=False,\n",
    "    total_epochs=0\n",
    ")\n",
    "\n",
    "logger.info(f'Total number of samples: \\t{len(train_set)}')\n",
    "\n",
    "data_dict_list = []\n",
    "logger.info('Loading samples')\n",
    "for idx, data_dict in enumerate(train_set):\n",
    "    logger.info(f'Loaded sample index: \\t{idx + 1}')\n",
    "    data_dict = train_set.collate_batch([data_dict])\n",
    "    data_dict_list.append(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pc(data_dict):\n",
    "    V.draw_scenes(\n",
    "        points=data_dict['points'][:, 1:], gt_boxes=data_dict['gt_boxes'][0]\n",
    "    )\n",
    "    return mlab.test_plot3d()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8913bbd34beb46aea46eb4e0e720491a"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "show_pc(data_dict_list[1])"
   ]
  },
  {
   "source": [
    "## Augmentation methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip_along_x(gt_boxes, points):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C)\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    enable = True\n",
    "    if enable:\n",
    "        gt_boxes[:, 1] = -gt_boxes[:, 1]\n",
    "        gt_boxes[:, 6] = -gt_boxes[:, 6]\n",
    "        points[:, 1] = -points[:, 1]\n",
    "\n",
    "        if gt_boxes.shape[1] > 8:\n",
    "            gt_boxes[:, 8] = -gt_boxes[:, 8]\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def random_flip_along_y(gt_boxes, points):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C)\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    enable = True\n",
    "    if enable:\n",
    "        gt_boxes[:, 0] = -gt_boxes[:, 0]\n",
    "        gt_boxes[:, 6] = -(gt_boxes[:, 6] + np.pi)\n",
    "        points[:, 0] = -points[:, 0]\n",
    "\n",
    "        if gt_boxes.shape[1] > 7:\n",
    "            gt_boxes[:, 7] = -gt_boxes[:, 7]\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7de58262dc04e9581c0290b2d58644e"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "flipped_y = deepcopy(data_dict_list[1])\n",
    "flipped_y['gt_boxes'][0], flipped_y['points'][:,1:] = random_flip_along_y(flipped_y['gt_boxes'][0], flipped_y['points'][:,1:])\n",
    "\n",
    "show_pc(flipped_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85596977cb30448f91e778358ec22abb"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "flipped_x = deepcopy(data_dict_list[1])\n",
    "flipped_x['gt_boxes'][0], flipped_x['points'][:,1:] = random_flip_along_x(flipped_x['gt_boxes'][0], flipped_x['points'][:,1:])\n",
    "\n",
    "show_pc(flipped_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_rotation(gt_boxes, points, rot_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7 + C), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        rot_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    noise_rotation = np.random.uniform(rot_range[0], rot_range[1])\n",
    "    points = common_utils.rotate_points_along_z(points[np.newaxis, :, :], np.array([noise_rotation]))[0]\n",
    "    gt_boxes[:, 0:3] = common_utils.rotate_points_along_z(gt_boxes[np.newaxis, :, 0:3], np.array([noise_rotation]))[0]\n",
    "    gt_boxes[:, 6] += noise_rotation\n",
    "    if gt_boxes.shape[1] > 8:\n",
    "        gt_boxes[:, 7:9] = common_utils.rotate_points_along_z(\n",
    "            np.hstack((gt_boxes[:, 7:9], np.zeros((gt_boxes.shape[0], 1))))[np.newaxis, :, :],\n",
    "            np.array([noise_rotation])\n",
    "        )[0][:, 0:2]\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e7a07d1f12143eca640e0586008d722"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "rotated = deepcopy(data_dict_list[1])\n",
    "rotated['gt_boxes'][0], rotated['points'][:,1:] = global_rotation(rotated['gt_boxes'][0], rotated['points'][:,1:], [-0.78539816, 0.78539816])\n",
    "\n",
    "show_pc(rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_scaling(gt_boxes, points, scale_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading]\n",
    "        points: (M, 3 + C),\n",
    "        scale_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if scale_range[1] - scale_range[0] < 1e-3:\n",
    "        return gt_boxes, points\n",
    "    noise_scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "    points[:, :3] *= noise_scale\n",
    "    gt_boxes[:, :6] *= noise_scale\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cecba8e8bb8b4d11b0585645578d51f9"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "scaled = deepcopy(data_dict_list[1])\n",
    "scaled['gt_boxes'][0], scaled['points'][:,1:] = global_scaling(scaled['gt_boxes'][0], scaled['points'][:, 1:], [0.2, 0.5])\n",
    "\n",
    "show_pc(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_translaction_along_x(gt_boxes, points, offset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset: float\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    points[:, 0] += offset\n",
    "    gt_boxes[:, 0] += offset\n",
    "\n",
    "    if gt_boxes.shape[1] > 7:\n",
    "        gt_boxes[:, 7] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def global_translaction_along_y(gt_boxes, points, offset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset: float\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    points[:, 1] += offset\n",
    "    gt_boxes[:, 1] += offset\n",
    "\n",
    "    if gt_boxes.shape[1] > 8:\n",
    "        gt_boxes[:, 8] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def global_translaction_along_z(gt_boxes, points, offset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset: float\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    points[:, 2] += offset\n",
    "    gt_boxes[:, 2] += offset\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aec29ff4f7b641eb8dce8f68a166e93f"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "translaction_x = deepcopy(data_dict_list[1])\n",
    "translaction_x['gt_boxes'][0], translaction_x['points'][:,1:] = global_translaction_along_x(translaction_x['gt_boxes'][0], translaction_x['points'][:, 1:], 20)\n",
    "\n",
    "show_pc(translaction_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64cab17d40e34f73aaec820fcff33219"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "translaction_y = deepcopy(data_dict_list[1])\n",
    "translaction_y['gt_boxes'][0], translaction_y['points'][:,1:] = global_translaction_along_y(translaction_y['gt_boxes'][0], translaction_y['points'][:, 1:], 20)\n",
    "\n",
    "show_pc(translaction_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea6960808a1647eaa7f01ce41ddc20c6"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "translaction_z = deepcopy(data_dict_list[1])\n",
    "translaction_z['gt_boxes'][0], translaction_z['points'][:,1:] = global_translaction_along_z(translaction_z['gt_boxes'][0], translaction_z['points'][:, 1:], 20)\n",
    "\n",
    "show_pc(translaction_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_points_in_box(points, gt_box):\n",
    "    filter_arr = []\n",
    "    for point in points:\n",
    "        x, y, z, dx, dy, dz = gt_box[0], gt_box[1], gt_box[2], gt_box[3], gt_box[4], gt_box[5]\n",
    "        if point[0] <= x + dx/2 and point[0] >= x - dx/2 \\\n",
    "            and point[1] <= y + dy/2 and point[1] >= y - dy/2 \\\n",
    "                and point[2] <= z + dz/2 and point[2] >= z - dz/2:\n",
    "                    filter_arr.append(True)\n",
    "        else:\n",
    "            filter_arr.append(False)\n",
    "\n",
    "    # points_in_box = points[filter_arr]\n",
    "    return filter_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ede880713ab2441f93968c6091cca436"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "points_to_filter = deepcopy(data_dict_list[1])\n",
    "filter_arr = filter_points_in_box(points_to_filter['points'][:,1:], points_to_filter['gt_boxes'][0][1])\n",
    "filtered_points = points_to_filter['points'][:,1:][filter_arr]\n",
    "\n",
    "V.draw_scenes(\n",
    "        points=filtered_points, gt_boxes=points_to_filter['gt_boxes'][0,1:]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_translaction_along_x(gt_boxes, points, offset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset: float\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    for box in gt_boxes:\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                point[0] += offset\n",
    "\n",
    "    gt_boxes[:, 0] += offset\n",
    "\n",
    "    if gt_boxes.shape[1] > 7:\n",
    "        gt_boxes[:, 7] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def local_translaction_along_y(gt_boxes, points, offset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset: float\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    for box in gt_boxes:\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                point[1] += offset\n",
    "\n",
    "    gt_boxes[:, 1] += offset\n",
    "\n",
    "    if gt_boxes.shape[1] > 8:\n",
    "        gt_boxes[:, 8] += offset\n",
    "\n",
    "    return gt_boxes, points\n",
    "\n",
    "def local_translaction_along_z(gt_boxes, points, offset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        offset: float\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    for box in gt_boxes:\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                point[2] += offset\n",
    "\n",
    "    gt_boxes[:, 2] += offset\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e4c28ba465f40b486b4c7509b80db90"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "local_translaction_x = deepcopy(data_dict_list[1])\n",
    "local_translaction_x['gt_boxes'][0], local_translaction_x['points'][:,1:] = local_translaction_along_x(local_translaction_x['gt_boxes'][0], local_translaction_x['points'][:, 1:], 10)\n",
    "\n",
    "show_pc(local_translaction_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d71401036c5d437ea795524f8196e1b1"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "local_translaction_y = deepcopy(data_dict_list[1])\n",
    "local_translaction_y['gt_boxes'][0], local_translaction_y['points'][:,1:] = local_translaction_along_y(local_translaction_y['gt_boxes'][0], local_translaction_y['points'][:, 1:], 10)\n",
    "\n",
    "show_pc(local_translaction_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8528bd0986f247f39e0210f0d918ac97"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "local_translaction_z = deepcopy(data_dict_list[1])\n",
    "local_translaction_z['gt_boxes'][0], local_translaction_z['points'][:,1:] = local_translaction_along_z(local_translaction_z['gt_boxes'][0], local_translaction_z['points'][:, 1:], 10)\n",
    "\n",
    "show_pc(local_translaction_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_scaling(gt_boxes, points, scale_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading]\n",
    "        points: (M, 3 + C),\n",
    "        scale_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if scale_range[1] - scale_range[0] < 1e-3:\n",
    "        return gt_boxes, points\n",
    "\n",
    "    noise_scale = np.random.uniform(scale_range[0], scale_range[1])\n",
    "    for box in gt_boxes:\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                # tranlation to axis center\n",
    "                point[0] -= box[0]\n",
    "                point[1] -= box[1]\n",
    "                point[2] -= box[2]\n",
    "\n",
    "                # apply scaling\n",
    "                point[:3] *= noise_scale\n",
    "\n",
    "                # tranlation back to original position\n",
    "                point[0] += box[0]\n",
    "                point[1] += box[1]\n",
    "                point[2] += box[2]\n",
    "\n",
    "    gt_boxes[:, 3:6] *= noise_scale\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "714a4f62567b48bd860f42ab67cfcb90"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "scaled_local = deepcopy(data_dict_list[1])\n",
    "scaled_local['gt_boxes'][0], scaled_local['points'][:,1:] = local_scaling(scaled_local['gt_boxes'][0], scaled_local['points'][:, 1:], [1.2, 1.5])\n",
    "\n",
    "show_pc(scaled_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_rotation(gt_boxes, points, rot_range):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        gt_boxes: (N, 7), [x, y, z, dx, dy, dz, heading, [vx], [vy]]\n",
    "        points: (M, 3 + C),\n",
    "        rot_range: [min, max]\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    noise_rotation = np.random.uniform(rot_range[0], rot_range[1])\n",
    "\n",
    "    for box in gt_boxes:\n",
    "        filter_arr = filter_points_in_box(points, box)\n",
    "        points_in_box = points[filter_arr]\n",
    "        for point in points:\n",
    "            if np.isin(point, points_in_box).all():\n",
    "                centroid_x = box[0]\n",
    "                centroid_y = box[1]\n",
    "                centroid_z = box[2]\n",
    "\n",
    "                #print(\"BEFORE:\\n\" + str(point))\n",
    "                # tranlation to axis center\n",
    "                point[0] -= centroid_x\n",
    "                point[1] -= centroid_y\n",
    "                point[2] -= centroid_z\n",
    "                box[0] -= centroid_x\n",
    "                box[1] -= centroid_y\n",
    "                box[2] -= centroid_z\n",
    "\n",
    "                # apply rotation\n",
    "                point[:] = common_utils.rotate_points_along_z(point[np.newaxis, np.newaxis, :], np.array([noise_rotation]))[0][0]\n",
    "                box[0:3] = common_utils.rotate_points_along_z(box[np.newaxis, np.newaxis, 0:3], np.array([noise_rotation]))[0][0]\n",
    "\n",
    "                # tranlation back to original position\n",
    "                point[0] += centroid_x\n",
    "                point[1] += centroid_y\n",
    "                point[2] += centroid_z\n",
    "                box[0] += centroid_x\n",
    "                box[1] += centroid_y\n",
    "                box[2] += centroid_z\n",
    "                #print(\"AFTER:\\n\" + str(point))\n",
    "\n",
    "    gt_boxes[:, 6] += noise_rotation\n",
    "    if gt_boxes.shape[1] > 8:\n",
    "        gt_boxes[:, 7:9] = common_utils.rotate_points_along_z(\n",
    "            np.hstack((gt_boxes[:, 7:9], np.zeros((gt_boxes.shape[0], 1))))[np.newaxis, :, :],\n",
    "            np.array([noise_rotation])\n",
    "        )[0][:, 0:2]\n",
    "\n",
    "    return gt_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x02X\\x00\\x00\\x02X\\x08\\x02\\x00\\x00\\x001\\x04\\x0f\\x8b\\xâ€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "705fd032bc8a4909b528e9ffad78463e"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "rotated_local = deepcopy(data_dict_list[1])\n",
    "rotated_local['gt_boxes'][0], rotated_local['points'][:,1:] = local_rotation(rotated_local['gt_boxes'][0], rotated_local['points'][:, 1:], [0.78539815, 0.78539816])\n",
    "\n",
    "show_pc(rotated_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}